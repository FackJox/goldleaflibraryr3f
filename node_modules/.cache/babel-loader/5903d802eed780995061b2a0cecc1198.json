{"ast":null,"code":"\"use strict\";\n\nvar __extends = this && this.__extends || function () {\n  var _extendStatics = function extendStatics(d, b) {\n    _extendStatics = Object.setPrototypeOf || {\n      __proto__: []\n    } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) {\n        if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p];\n      }\n    };\n    return _extendStatics(d, b);\n  };\n  return function (d, b) {\n    if (typeof b !== \"function\" && b !== null) throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n    _extendStatics(d, b);\n    function __() {\n      this.constructor = d;\n    }\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\nvar __importDefault = this && this.__importDefault || function (mod) {\n  return mod && mod.__esModule ? mod : {\n    \"default\": mod\n  };\n};\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.charCodeToOptimizedIndex = exports.minOptimizationVal = exports.buildLineBreakIssueMessage = exports.LineTerminatorOptimizedTester = exports.isShortPattern = exports.isCustomPattern = exports.cloneEmptyGroups = exports.performWarningRuntimeChecks = exports.performRuntimeChecks = exports.addStickyFlag = exports.addStartOfInput = exports.findUnreachablePatterns = exports.findModesThatDoNotExist = exports.findInvalidGroupType = exports.findDuplicatePatterns = exports.findUnsupportedFlags = exports.findStartOfInputAnchor = exports.findEmptyMatchRegExps = exports.findEndOfInputAnchor = exports.findInvalidPatterns = exports.findMissingPatterns = exports.validatePatterns = exports.analyzeTokenTypes = exports.enableSticky = exports.disableSticky = exports.SUPPORT_STICKY = exports.MODES = exports.DEFAULT_MODE = void 0;\nvar regexp_to_ast_1 = require(\"regexp-to-ast\");\nvar lexer_public_1 = require(\"./lexer_public\");\nvar first_1 = __importDefault(require(\"lodash/first\"));\nvar isEmpty_1 = __importDefault(require(\"lodash/isEmpty\"));\nvar compact_1 = __importDefault(require(\"lodash/compact\"));\nvar isArray_1 = __importDefault(require(\"lodash/isArray\"));\nvar values_1 = __importDefault(require(\"lodash/values\"));\nvar flatten_1 = __importDefault(require(\"lodash/flatten\"));\nvar reject_1 = __importDefault(require(\"lodash/reject\"));\nvar difference_1 = __importDefault(require(\"lodash/difference\"));\nvar indexOf_1 = __importDefault(require(\"lodash/indexOf\"));\nvar map_1 = __importDefault(require(\"lodash/map\"));\nvar forEach_1 = __importDefault(require(\"lodash/forEach\"));\nvar isString_1 = __importDefault(require(\"lodash/isString\"));\nvar isFunction_1 = __importDefault(require(\"lodash/isFunction\"));\nvar isUndefined_1 = __importDefault(require(\"lodash/isUndefined\"));\nvar find_1 = __importDefault(require(\"lodash/find\"));\nvar has_1 = __importDefault(require(\"lodash/has\"));\nvar keys_1 = __importDefault(require(\"lodash/keys\"));\nvar isRegExp_1 = __importDefault(require(\"lodash/isRegExp\"));\nvar filter_1 = __importDefault(require(\"lodash/filter\"));\nvar defaults_1 = __importDefault(require(\"lodash/defaults\"));\nvar reduce_1 = __importDefault(require(\"lodash/reduce\"));\nvar includes_1 = __importDefault(require(\"lodash/includes\"));\nvar utils_1 = require(\"@chevrotain/utils\");\nvar reg_exp_1 = require(\"./reg_exp\");\nvar reg_exp_parser_1 = require(\"./reg_exp_parser\");\nvar PATTERN = \"PATTERN\";\nexports.DEFAULT_MODE = \"defaultMode\";\nexports.MODES = \"modes\";\nexports.SUPPORT_STICKY = typeof new RegExp(\"(?:)\").sticky === \"boolean\";\nfunction disableSticky() {\n  exports.SUPPORT_STICKY = false;\n}\nexports.disableSticky = disableSticky;\nfunction enableSticky() {\n  exports.SUPPORT_STICKY = true;\n}\nexports.enableSticky = enableSticky;\nfunction analyzeTokenTypes(tokenTypes, options) {\n  options = (0, defaults_1.default)(options, {\n    useSticky: exports.SUPPORT_STICKY,\n    debug: false,\n    safeMode: false,\n    positionTracking: \"full\",\n    lineTerminatorCharacters: [\"\\r\", \"\\n\"],\n    tracer: function tracer(msg, action) {\n      return action();\n    }\n  });\n  var tracer = options.tracer;\n  tracer(\"initCharCodeToOptimizedIndexMap\", function () {\n    initCharCodeToOptimizedIndexMap();\n  });\n  var onlyRelevantTypes;\n  tracer(\"Reject Lexer.NA\", function () {\n    onlyRelevantTypes = (0, reject_1.default)(tokenTypes, function (currType) {\n      return currType[PATTERN] === lexer_public_1.Lexer.NA;\n    });\n  });\n  var hasCustom = false;\n  var allTransformedPatterns;\n  tracer(\"Transform Patterns\", function () {\n    hasCustom = false;\n    allTransformedPatterns = (0, map_1.default)(onlyRelevantTypes, function (currType) {\n      var currPattern = currType[PATTERN];\n      /* istanbul ignore else */\n      if ((0, isRegExp_1.default)(currPattern)) {\n        var regExpSource = currPattern.source;\n        if (regExpSource.length === 1 &&\n        // only these regExp meta characters which can appear in a length one regExp\n        regExpSource !== \"^\" && regExpSource !== \"$\" && regExpSource !== \".\" && !currPattern.ignoreCase) {\n          return regExpSource;\n        } else if (regExpSource.length === 2 && regExpSource[0] === \"\\\\\" &&\n        // not a meta character\n        !(0, includes_1.default)([\"d\", \"D\", \"s\", \"S\", \"t\", \"r\", \"n\", \"t\", \"0\", \"c\", \"b\", \"B\", \"f\", \"v\", \"w\", \"W\"], regExpSource[1])) {\n          // escaped meta Characters: /\\+/ /\\[/\n          // or redundant escaping: /\\a/\n          // without the escaping \"\\\"\n          return regExpSource[1];\n        } else {\n          return options.useSticky ? addStickyFlag(currPattern) : addStartOfInput(currPattern);\n        }\n      } else if ((0, isFunction_1.default)(currPattern)) {\n        hasCustom = true;\n        // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n        return {\n          exec: currPattern\n        };\n      } else if (typeof currPattern === \"object\") {\n        hasCustom = true;\n        // ICustomPattern\n        return currPattern;\n      } else if (typeof currPattern === \"string\") {\n        if (currPattern.length === 1) {\n          return currPattern;\n        } else {\n          var escapedRegExpString = currPattern.replace(/[\\\\^$.*+?()[\\]{}|]/g, \"\\\\$&\");\n          var wrappedRegExp = new RegExp(escapedRegExpString);\n          return options.useSticky ? addStickyFlag(wrappedRegExp) : addStartOfInput(wrappedRegExp);\n        }\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n  });\n  var patternIdxToType;\n  var patternIdxToGroup;\n  var patternIdxToLongerAltIdxArr;\n  var patternIdxToPushMode;\n  var patternIdxToPopMode;\n  tracer(\"misc mapping\", function () {\n    patternIdxToType = (0, map_1.default)(onlyRelevantTypes, function (currType) {\n      return currType.tokenTypeIdx;\n    });\n    patternIdxToGroup = (0, map_1.default)(onlyRelevantTypes, function (clazz) {\n      var groupName = clazz.GROUP;\n      /* istanbul ignore next */\n      if (groupName === lexer_public_1.Lexer.SKIPPED) {\n        return undefined;\n      } else if ((0, isString_1.default)(groupName)) {\n        return groupName;\n      } else if ((0, isUndefined_1.default)(groupName)) {\n        return false;\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n    patternIdxToLongerAltIdxArr = (0, map_1.default)(onlyRelevantTypes, function (clazz) {\n      var longerAltType = clazz.LONGER_ALT;\n      if (longerAltType) {\n        var longerAltIdxArr = (0, isArray_1.default)(longerAltType) ? (0, map_1.default)(longerAltType, function (type) {\n          return (0, indexOf_1.default)(onlyRelevantTypes, type);\n        }) : [(0, indexOf_1.default)(onlyRelevantTypes, longerAltType)];\n        return longerAltIdxArr;\n      }\n    });\n    patternIdxToPushMode = (0, map_1.default)(onlyRelevantTypes, function (clazz) {\n      return clazz.PUSH_MODE;\n    });\n    patternIdxToPopMode = (0, map_1.default)(onlyRelevantTypes, function (clazz) {\n      return (0, has_1.default)(clazz, \"POP_MODE\");\n    });\n  });\n  var patternIdxToCanLineTerminator;\n  tracer(\"Line Terminator Handling\", function () {\n    var lineTerminatorCharCodes = getCharCodes(options.lineTerminatorCharacters);\n    patternIdxToCanLineTerminator = (0, map_1.default)(onlyRelevantTypes, function (tokType) {\n      return false;\n    });\n    if (options.positionTracking !== \"onlyOffset\") {\n      patternIdxToCanLineTerminator = (0, map_1.default)(onlyRelevantTypes, function (tokType) {\n        if ((0, has_1.default)(tokType, \"LINE_BREAKS\")) {\n          return !!tokType.LINE_BREAKS;\n        } else {\n          return checkLineBreaksIssues(tokType, lineTerminatorCharCodes) === false && (0, reg_exp_1.canMatchCharCode)(lineTerminatorCharCodes, tokType.PATTERN);\n        }\n      });\n    }\n  });\n  var patternIdxToIsCustom;\n  var patternIdxToShort;\n  var emptyGroups;\n  var patternIdxToConfig;\n  tracer(\"Misc Mapping #2\", function () {\n    patternIdxToIsCustom = (0, map_1.default)(onlyRelevantTypes, isCustomPattern);\n    patternIdxToShort = (0, map_1.default)(allTransformedPatterns, isShortPattern);\n    emptyGroups = (0, reduce_1.default)(onlyRelevantTypes, function (acc, clazz) {\n      var groupName = clazz.GROUP;\n      if ((0, isString_1.default)(groupName) && !(groupName === lexer_public_1.Lexer.SKIPPED)) {\n        acc[groupName] = [];\n      }\n      return acc;\n    }, {});\n    patternIdxToConfig = (0, map_1.default)(allTransformedPatterns, function (x, idx) {\n      return {\n        pattern: allTransformedPatterns[idx],\n        longerAlt: patternIdxToLongerAltIdxArr[idx],\n        canLineTerminator: patternIdxToCanLineTerminator[idx],\n        isCustom: patternIdxToIsCustom[idx],\n        short: patternIdxToShort[idx],\n        group: patternIdxToGroup[idx],\n        push: patternIdxToPushMode[idx],\n        pop: patternIdxToPopMode[idx],\n        tokenTypeIdx: patternIdxToType[idx],\n        tokenType: onlyRelevantTypes[idx]\n      };\n    });\n  });\n  var canBeOptimized = true;\n  var charCodeToPatternIdxToConfig = [];\n  if (!options.safeMode) {\n    tracer(\"First Char Optimization\", function () {\n      charCodeToPatternIdxToConfig = (0, reduce_1.default)(onlyRelevantTypes, function (result, currTokType, idx) {\n        if (typeof currTokType.PATTERN === \"string\") {\n          var charCode = currTokType.PATTERN.charCodeAt(0);\n          var optimizedIdx = charCodeToOptimizedIndex(charCode);\n          addToMapOfArrays(result, optimizedIdx, patternIdxToConfig[idx]);\n        } else if ((0, isArray_1.default)(currTokType.START_CHARS_HINT)) {\n          var lastOptimizedIdx_1;\n          (0, forEach_1.default)(currTokType.START_CHARS_HINT, function (charOrInt) {\n            var charCode = typeof charOrInt === \"string\" ? charOrInt.charCodeAt(0) : charOrInt;\n            var currOptimizedIdx = charCodeToOptimizedIndex(charCode);\n            // Avoid adding the config multiple times\n            /* istanbul ignore else */\n            // - Difficult to check this scenario effects as it is only a performance\n            //   optimization that does not change correctness\n            if (lastOptimizedIdx_1 !== currOptimizedIdx) {\n              lastOptimizedIdx_1 = currOptimizedIdx;\n              addToMapOfArrays(result, currOptimizedIdx, patternIdxToConfig[idx]);\n            }\n          });\n        } else if ((0, isRegExp_1.default)(currTokType.PATTERN)) {\n          if (currTokType.PATTERN.unicode) {\n            canBeOptimized = false;\n            if (options.ensureOptimizations) {\n              (0, utils_1.PRINT_ERROR)(\"\".concat(reg_exp_1.failedOptimizationPrefixMsg) + \"\\tUnable to analyze < \".concat(currTokType.PATTERN.toString(), \" > pattern.\\n\") + \"\\tThe regexp unicode flag is not currently supported by the regexp-to-ast library.\\n\" + \"\\tThis will disable the lexer's first char optimizations.\\n\" + \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNICODE_OPTIMIZE\");\n            }\n          } else {\n            var optimizedCodes = (0, reg_exp_1.getOptimizedStartCodesIndices)(currTokType.PATTERN, options.ensureOptimizations);\n            /* istanbul ignore if */\n            // start code will only be empty given an empty regExp or failure of regexp-to-ast library\n            // the first should be a different validation and the second cannot be tested.\n            if ((0, isEmpty_1.default)(optimizedCodes)) {\n              // we cannot understand what codes may start possible matches\n              // The optimization correctness requires knowing start codes for ALL patterns.\n              // Not actually sure this is an error, no debug message\n              canBeOptimized = false;\n            }\n            (0, forEach_1.default)(optimizedCodes, function (code) {\n              addToMapOfArrays(result, code, patternIdxToConfig[idx]);\n            });\n          }\n        } else {\n          if (options.ensureOptimizations) {\n            (0, utils_1.PRINT_ERROR)(\"\".concat(reg_exp_1.failedOptimizationPrefixMsg) + \"\\tTokenType: <\".concat(currTokType.name, \"> is using a custom token pattern without providing <start_chars_hint> parameter.\\n\") + \"\\tThis will disable the lexer's first char optimizations.\\n\" + \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_OPTIMIZE\");\n          }\n          canBeOptimized = false;\n        }\n        return result;\n      }, []);\n    });\n  }\n  return {\n    emptyGroups: emptyGroups,\n    patternIdxToConfig: patternIdxToConfig,\n    charCodeToPatternIdxToConfig: charCodeToPatternIdxToConfig,\n    hasCustom: hasCustom,\n    canBeOptimized: canBeOptimized\n  };\n}\nexports.analyzeTokenTypes = analyzeTokenTypes;\nfunction validatePatterns(tokenTypes, validModesNames) {\n  var errors = [];\n  var missingResult = findMissingPatterns(tokenTypes);\n  errors = errors.concat(missingResult.errors);\n  var invalidResult = findInvalidPatterns(missingResult.valid);\n  var validTokenTypes = invalidResult.valid;\n  errors = errors.concat(invalidResult.errors);\n  errors = errors.concat(validateRegExpPattern(validTokenTypes));\n  errors = errors.concat(findInvalidGroupType(validTokenTypes));\n  errors = errors.concat(findModesThatDoNotExist(validTokenTypes, validModesNames));\n  errors = errors.concat(findUnreachablePatterns(validTokenTypes));\n  return errors;\n}\nexports.validatePatterns = validatePatterns;\nfunction validateRegExpPattern(tokenTypes) {\n  var errors = [];\n  var withRegExpPatterns = (0, filter_1.default)(tokenTypes, function (currTokType) {\n    return (0, isRegExp_1.default)(currTokType[PATTERN]);\n  });\n  errors = errors.concat(findEndOfInputAnchor(withRegExpPatterns));\n  errors = errors.concat(findStartOfInputAnchor(withRegExpPatterns));\n  errors = errors.concat(findUnsupportedFlags(withRegExpPatterns));\n  errors = errors.concat(findDuplicatePatterns(withRegExpPatterns));\n  errors = errors.concat(findEmptyMatchRegExps(withRegExpPatterns));\n  return errors;\n}\nfunction findMissingPatterns(tokenTypes) {\n  var tokenTypesWithMissingPattern = (0, filter_1.default)(tokenTypes, function (currType) {\n    return !(0, has_1.default)(currType, PATTERN);\n  });\n  var errors = (0, map_1.default)(tokenTypesWithMissingPattern, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- missing static 'PATTERN' property\",\n      type: lexer_public_1.LexerDefinitionErrorType.MISSING_PATTERN,\n      tokenTypes: [currType]\n    };\n  });\n  var valid = (0, difference_1.default)(tokenTypes, tokenTypesWithMissingPattern);\n  return {\n    errors: errors,\n    valid: valid\n  };\n}\nexports.findMissingPatterns = findMissingPatterns;\nfunction findInvalidPatterns(tokenTypes) {\n  var tokenTypesWithInvalidPattern = (0, filter_1.default)(tokenTypes, function (currType) {\n    var pattern = currType[PATTERN];\n    return !(0, isRegExp_1.default)(pattern) && !(0, isFunction_1.default)(pattern) && !(0, has_1.default)(pattern, \"exec\") && !(0, isString_1.default)(pattern);\n  });\n  var errors = (0, map_1.default)(tokenTypesWithInvalidPattern, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' can only be a RegExp, a\" + \" Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\",\n      type: lexer_public_1.LexerDefinitionErrorType.INVALID_PATTERN,\n      tokenTypes: [currType]\n    };\n  });\n  var valid = (0, difference_1.default)(tokenTypes, tokenTypesWithInvalidPattern);\n  return {\n    errors: errors,\n    valid: valid\n  };\n}\nexports.findInvalidPatterns = findInvalidPatterns;\nvar end_of_input = /[^\\\\][$]/;\nfunction findEndOfInputAnchor(tokenTypes) {\n  var EndAnchorFinder = /** @class */function (_super) {\n    __extends(EndAnchorFinder, _super);\n    function EndAnchorFinder() {\n      var _this = _super !== null && _super.apply(this, arguments) || this;\n      _this.found = false;\n      return _this;\n    }\n    EndAnchorFinder.prototype.visitEndAnchor = function (node) {\n      this.found = true;\n    };\n    return EndAnchorFinder;\n  }(regexp_to_ast_1.BaseRegExpVisitor);\n  var invalidRegex = (0, filter_1.default)(tokenTypes, function (currType) {\n    var pattern = currType.PATTERN;\n    try {\n      var regexpAst = (0, reg_exp_parser_1.getRegExpAst)(pattern);\n      var endAnchorVisitor = new EndAnchorFinder();\n      endAnchorVisitor.visit(regexpAst);\n      return endAnchorVisitor.found;\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return end_of_input.test(pattern.source);\n    }\n  });\n  var errors = (0, map_1.default)(invalidRegex, function (currType) {\n    return {\n      message: \"Unexpected RegExp Anchor Error:\\n\" + \"\\tToken Type: ->\" + currType.name + \"<- static 'PATTERN' cannot contain end of input anchor '$'\\n\" + \"\\tSee chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" + \"\\tfor details.\",\n      type: lexer_public_1.LexerDefinitionErrorType.EOI_ANCHOR_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\nexports.findEndOfInputAnchor = findEndOfInputAnchor;\nfunction findEmptyMatchRegExps(tokenTypes) {\n  var matchesEmptyString = (0, filter_1.default)(tokenTypes, function (currType) {\n    var pattern = currType.PATTERN;\n    return pattern.test(\"\");\n  });\n  var errors = (0, map_1.default)(matchesEmptyString, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' must not match an empty string\",\n      type: lexer_public_1.LexerDefinitionErrorType.EMPTY_MATCH_PATTERN,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\nexports.findEmptyMatchRegExps = findEmptyMatchRegExps;\nvar start_of_input = /[^\\\\[][\\^]|^\\^/;\nfunction findStartOfInputAnchor(tokenTypes) {\n  var StartAnchorFinder = /** @class */function (_super) {\n    __extends(StartAnchorFinder, _super);\n    function StartAnchorFinder() {\n      var _this = _super !== null && _super.apply(this, arguments) || this;\n      _this.found = false;\n      return _this;\n    }\n    StartAnchorFinder.prototype.visitStartAnchor = function (node) {\n      this.found = true;\n    };\n    return StartAnchorFinder;\n  }(regexp_to_ast_1.BaseRegExpVisitor);\n  var invalidRegex = (0, filter_1.default)(tokenTypes, function (currType) {\n    var pattern = currType.PATTERN;\n    try {\n      var regexpAst = (0, reg_exp_parser_1.getRegExpAst)(pattern);\n      var startAnchorVisitor = new StartAnchorFinder();\n      startAnchorVisitor.visit(regexpAst);\n      return startAnchorVisitor.found;\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return start_of_input.test(pattern.source);\n    }\n  });\n  var errors = (0, map_1.default)(invalidRegex, function (currType) {\n    return {\n      message: \"Unexpected RegExp Anchor Error:\\n\" + \"\\tToken Type: ->\" + currType.name + \"<- static 'PATTERN' cannot contain start of input anchor '^'\\n\" + \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" + \"\\tfor details.\",\n      type: lexer_public_1.LexerDefinitionErrorType.SOI_ANCHOR_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\nexports.findStartOfInputAnchor = findStartOfInputAnchor;\nfunction findUnsupportedFlags(tokenTypes) {\n  var invalidFlags = (0, filter_1.default)(tokenTypes, function (currType) {\n    var pattern = currType[PATTERN];\n    return pattern instanceof RegExp && (pattern.multiline || pattern.global);\n  });\n  var errors = (0, map_1.default)(invalidFlags, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' may NOT contain global('g') or multiline('m')\",\n      type: lexer_public_1.LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\nexports.findUnsupportedFlags = findUnsupportedFlags;\n// This can only test for identical duplicate RegExps, not semantically equivalent ones.\nfunction findDuplicatePatterns(tokenTypes) {\n  var found = [];\n  var identicalPatterns = (0, map_1.default)(tokenTypes, function (outerType) {\n    return (0, reduce_1.default)(tokenTypes, function (result, innerType) {\n      if (outerType.PATTERN.source === innerType.PATTERN.source && !(0, includes_1.default)(found, innerType) && innerType.PATTERN !== lexer_public_1.Lexer.NA) {\n        // this avoids duplicates in the result, each Token Type may only appear in one \"set\"\n        // in essence we are creating Equivalence classes on equality relation.\n        found.push(innerType);\n        result.push(innerType);\n        return result;\n      }\n      return result;\n    }, []);\n  });\n  identicalPatterns = (0, compact_1.default)(identicalPatterns);\n  var duplicatePatterns = (0, filter_1.default)(identicalPatterns, function (currIdenticalSet) {\n    return currIdenticalSet.length > 1;\n  });\n  var errors = (0, map_1.default)(duplicatePatterns, function (setOfIdentical) {\n    var tokenTypeNames = (0, map_1.default)(setOfIdentical, function (currType) {\n      return currType.name;\n    });\n    var dupPatternSrc = (0, first_1.default)(setOfIdentical).PATTERN;\n    return {\n      message: \"The same RegExp pattern ->\".concat(dupPatternSrc, \"<-\") + \"has been used in all of the following Token Types: \".concat(tokenTypeNames.join(\", \"), \" <-\"),\n      type: lexer_public_1.LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,\n      tokenTypes: setOfIdentical\n    };\n  });\n  return errors;\n}\nexports.findDuplicatePatterns = findDuplicatePatterns;\nfunction findInvalidGroupType(tokenTypes) {\n  var invalidTypes = (0, filter_1.default)(tokenTypes, function (clazz) {\n    if (!(0, has_1.default)(clazz, \"GROUP\")) {\n      return false;\n    }\n    var group = clazz.GROUP;\n    return group !== lexer_public_1.Lexer.SKIPPED && group !== lexer_public_1.Lexer.NA && !(0, isString_1.default)(group);\n  });\n  var errors = (0, map_1.default)(invalidTypes, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\",\n      type: lexer_public_1.LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\nexports.findInvalidGroupType = findInvalidGroupType;\nfunction findModesThatDoNotExist(tokenTypes, validModes) {\n  var invalidModes = (0, filter_1.default)(tokenTypes, function (clazz) {\n    return clazz.PUSH_MODE !== undefined && !(0, includes_1.default)(validModes, clazz.PUSH_MODE);\n  });\n  var errors = (0, map_1.default)(invalidModes, function (tokType) {\n    var msg = \"Token Type: ->\".concat(tokType.name, \"<- static 'PUSH_MODE' value cannot refer to a Lexer Mode ->\").concat(tokType.PUSH_MODE, \"<-\") + \"which does not exist\";\n    return {\n      message: msg,\n      type: lexer_public_1.LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,\n      tokenTypes: [tokType]\n    };\n  });\n  return errors;\n}\nexports.findModesThatDoNotExist = findModesThatDoNotExist;\nfunction findUnreachablePatterns(tokenTypes) {\n  var errors = [];\n  var canBeTested = (0, reduce_1.default)(tokenTypes, function (result, tokType, idx) {\n    var pattern = tokType.PATTERN;\n    if (pattern === lexer_public_1.Lexer.NA) {\n      return result;\n    }\n    // a more comprehensive validation for all forms of regExps would require\n    // deeper regExp analysis capabilities\n    if ((0, isString_1.default)(pattern)) {\n      result.push({\n        str: pattern,\n        idx: idx,\n        tokenType: tokType\n      });\n    } else if ((0, isRegExp_1.default)(pattern) && noMetaChar(pattern)) {\n      result.push({\n        str: pattern.source,\n        idx: idx,\n        tokenType: tokType\n      });\n    }\n    return result;\n  }, []);\n  (0, forEach_1.default)(tokenTypes, function (tokType, testIdx) {\n    (0, forEach_1.default)(canBeTested, function (_a) {\n      var str = _a.str,\n        idx = _a.idx,\n        tokenType = _a.tokenType;\n      if (testIdx < idx && testTokenType(str, tokType.PATTERN)) {\n        var msg = \"Token: ->\".concat(tokenType.name, \"<- can never be matched.\\n\") + \"Because it appears AFTER the Token Type ->\".concat(tokType.name, \"<-\") + \"in the lexer's definition.\\n\" + \"See https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNREACHABLE\";\n        errors.push({\n          message: msg,\n          type: lexer_public_1.LexerDefinitionErrorType.UNREACHABLE_PATTERN,\n          tokenTypes: [tokType, tokenType]\n        });\n      }\n    });\n  });\n  return errors;\n}\nexports.findUnreachablePatterns = findUnreachablePatterns;\nfunction testTokenType(str, pattern) {\n  /* istanbul ignore else */\n  if ((0, isRegExp_1.default)(pattern)) {\n    var regExpArray = pattern.exec(str);\n    return regExpArray !== null && regExpArray.index === 0;\n  } else if ((0, isFunction_1.default)(pattern)) {\n    // maintain the API of custom patterns\n    return pattern(str, 0, [], {});\n  } else if ((0, has_1.default)(pattern, \"exec\")) {\n    // maintain the API of custom patterns\n    return pattern.exec(str, 0, [], {});\n  } else if (typeof pattern === \"string\") {\n    return pattern === str;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\nfunction noMetaChar(regExp) {\n  //https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp\n  var metaChars = [\".\", \"\\\\\", \"[\", \"]\", \"|\", \"^\", \"$\", \"(\", \")\", \"?\", \"*\", \"+\", \"{\"];\n  return (0, find_1.default)(metaChars, function (char) {\n    return regExp.source.indexOf(char) !== -1;\n  }) === undefined;\n}\nfunction addStartOfInput(pattern) {\n  var flags = pattern.ignoreCase ? \"i\" : \"\";\n  // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n  return new RegExp(\"^(?:\".concat(pattern.source, \")\"), flags);\n}\nexports.addStartOfInput = addStartOfInput;\nfunction addStickyFlag(pattern) {\n  var flags = pattern.ignoreCase ? \"iy\" : \"y\";\n  // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n  return new RegExp(\"\".concat(pattern.source), flags);\n}\nexports.addStickyFlag = addStickyFlag;\nfunction performRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n  var errors = [];\n  // some run time checks to help the end users.\n  if (!(0, has_1.default)(lexerDefinition, exports.DEFAULT_MODE)) {\n    errors.push({\n      message: \"A MultiMode Lexer cannot be initialized without a <\" + exports.DEFAULT_MODE + \"> property in its definition\\n\",\n      type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\n    });\n  }\n  if (!(0, has_1.default)(lexerDefinition, exports.MODES)) {\n    errors.push({\n      message: \"A MultiMode Lexer cannot be initialized without a <\" + exports.MODES + \"> property in its definition\\n\",\n      type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\n    });\n  }\n  if ((0, has_1.default)(lexerDefinition, exports.MODES) && (0, has_1.default)(lexerDefinition, exports.DEFAULT_MODE) && !(0, has_1.default)(lexerDefinition.modes, lexerDefinition.defaultMode)) {\n    errors.push({\n      message: \"A MultiMode Lexer cannot be initialized with a \".concat(exports.DEFAULT_MODE, \": <\").concat(lexerDefinition.defaultMode, \">\") + \"which does not exist\\n\",\n      type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\n    });\n  }\n  if ((0, has_1.default)(lexerDefinition, exports.MODES)) {\n    (0, forEach_1.default)(lexerDefinition.modes, function (currModeValue, currModeName) {\n      (0, forEach_1.default)(currModeValue, function (currTokType, currIdx) {\n        if ((0, isUndefined_1.default)(currTokType)) {\n          errors.push({\n            message: \"A Lexer cannot be initialized using an undefined Token Type. Mode:\" + \"<\".concat(currModeName, \"> at index: <\").concat(currIdx, \">\\n\"),\n            type: lexer_public_1.LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\n          });\n        } else if ((0, has_1.default)(currTokType, \"LONGER_ALT\")) {\n          var longerAlt = (0, isArray_1.default)(currTokType.LONGER_ALT) ? currTokType.LONGER_ALT : [currTokType.LONGER_ALT];\n          (0, forEach_1.default)(longerAlt, function (currLongerAlt) {\n            if (!(0, isUndefined_1.default)(currLongerAlt) && !(0, includes_1.default)(currModeValue, currLongerAlt)) {\n              errors.push({\n                message: \"A MultiMode Lexer cannot be initialized with a longer_alt <\".concat(currLongerAlt.name, \"> on token <\").concat(currTokType.name, \"> outside of mode <\").concat(currModeName, \">\\n\"),\n                type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\n              });\n            }\n          });\n        }\n      });\n    });\n  }\n  return errors;\n}\nexports.performRuntimeChecks = performRuntimeChecks;\nfunction performWarningRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n  var warnings = [];\n  var hasAnyLineBreak = false;\n  var allTokenTypes = (0, compact_1.default)((0, flatten_1.default)((0, values_1.default)(lexerDefinition.modes)));\n  var concreteTokenTypes = (0, reject_1.default)(allTokenTypes, function (currType) {\n    return currType[PATTERN] === lexer_public_1.Lexer.NA;\n  });\n  var terminatorCharCodes = getCharCodes(lineTerminatorCharacters);\n  if (trackLines) {\n    (0, forEach_1.default)(concreteTokenTypes, function (tokType) {\n      var currIssue = checkLineBreaksIssues(tokType, terminatorCharCodes);\n      if (currIssue !== false) {\n        var message = buildLineBreakIssueMessage(tokType, currIssue);\n        var warningDescriptor = {\n          message: message,\n          type: currIssue.issue,\n          tokenType: tokType\n        };\n        warnings.push(warningDescriptor);\n      } else {\n        // we don't want to attempt to scan if the user explicitly specified the line_breaks option.\n        if ((0, has_1.default)(tokType, \"LINE_BREAKS\")) {\n          if (tokType.LINE_BREAKS === true) {\n            hasAnyLineBreak = true;\n          }\n        } else {\n          if ((0, reg_exp_1.canMatchCharCode)(terminatorCharCodes, tokType.PATTERN)) {\n            hasAnyLineBreak = true;\n          }\n        }\n      }\n    });\n  }\n  if (trackLines && !hasAnyLineBreak) {\n    warnings.push({\n      message: \"Warning: No LINE_BREAKS Found.\\n\" + \"\\tThis Lexer has been defined to track line and column information,\\n\" + \"\\tBut none of the Token Types can be identified as matching a line terminator.\\n\" + \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#LINE_BREAKS \\n\" + \"\\tfor details.\",\n      type: lexer_public_1.LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS\n    });\n  }\n  return warnings;\n}\nexports.performWarningRuntimeChecks = performWarningRuntimeChecks;\nfunction cloneEmptyGroups(emptyGroups) {\n  var clonedResult = {};\n  var groupKeys = (0, keys_1.default)(emptyGroups);\n  (0, forEach_1.default)(groupKeys, function (currKey) {\n    var currGroupValue = emptyGroups[currKey];\n    /* istanbul ignore else */\n    if ((0, isArray_1.default)(currGroupValue)) {\n      clonedResult[currKey] = [];\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  });\n  return clonedResult;\n}\nexports.cloneEmptyGroups = cloneEmptyGroups;\n// TODO: refactor to avoid duplication\nfunction isCustomPattern(tokenType) {\n  var pattern = tokenType.PATTERN;\n  /* istanbul ignore else */\n  if ((0, isRegExp_1.default)(pattern)) {\n    return false;\n  } else if ((0, isFunction_1.default)(pattern)) {\n    // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n    return true;\n  } else if ((0, has_1.default)(pattern, \"exec\")) {\n    // ICustomPattern\n    return true;\n  } else if ((0, isString_1.default)(pattern)) {\n    return false;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\nexports.isCustomPattern = isCustomPattern;\nfunction isShortPattern(pattern) {\n  if ((0, isString_1.default)(pattern) && pattern.length === 1) {\n    return pattern.charCodeAt(0);\n  } else {\n    return false;\n  }\n}\nexports.isShortPattern = isShortPattern;\n/**\n * Faster than using a RegExp for default newline detection during lexing.\n */\nexports.LineTerminatorOptimizedTester = {\n  // implements /\\n|\\r\\n?/g.test\n  test: function test(text) {\n    var len = text.length;\n    for (var i = this.lastIndex; i < len; i++) {\n      var c = text.charCodeAt(i);\n      if (c === 10) {\n        this.lastIndex = i + 1;\n        return true;\n      } else if (c === 13) {\n        if (text.charCodeAt(i + 1) === 10) {\n          this.lastIndex = i + 2;\n        } else {\n          this.lastIndex = i + 1;\n        }\n        return true;\n      }\n    }\n    return false;\n  },\n  lastIndex: 0\n};\nfunction checkLineBreaksIssues(tokType, lineTerminatorCharCodes) {\n  if ((0, has_1.default)(tokType, \"LINE_BREAKS\")) {\n    // if the user explicitly declared the line_breaks option we will respect their choice\n    // and assume it is correct.\n    return false;\n  } else {\n    /* istanbul ignore else */\n    if ((0, isRegExp_1.default)(tokType.PATTERN)) {\n      try {\n        // TODO: why is the casting suddenly needed?\n        (0, reg_exp_1.canMatchCharCode)(lineTerminatorCharCodes, tokType.PATTERN);\n      } catch (e) {\n        /* istanbul ignore next - to test this we would have to mock <canMatchCharCode> to throw an error */\n        return {\n          issue: lexer_public_1.LexerDefinitionErrorType.IDENTIFY_TERMINATOR,\n          errMsg: e.message\n        };\n      }\n      return false;\n    } else if ((0, isString_1.default)(tokType.PATTERN)) {\n      // string literal patterns can always be analyzed to detect line terminator usage\n      return false;\n    } else if (isCustomPattern(tokType)) {\n      // custom token types\n      return {\n        issue: lexer_public_1.LexerDefinitionErrorType.CUSTOM_LINE_BREAK\n      };\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n}\nfunction buildLineBreakIssueMessage(tokType, details) {\n  /* istanbul ignore else */\n  if (details.issue === lexer_public_1.LexerDefinitionErrorType.IDENTIFY_TERMINATOR) {\n    return \"Warning: unable to identify line terminator usage in pattern.\\n\" + \"\\tThe problem is in the <\".concat(tokType.name, \"> Token Type\\n\") + \"\\t Root cause: \".concat(details.errMsg, \".\\n\") + \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#IDENTIFY_TERMINATOR\";\n  } else if (details.issue === lexer_public_1.LexerDefinitionErrorType.CUSTOM_LINE_BREAK) {\n    return \"Warning: A Custom Token Pattern should specify the <line_breaks> option.\\n\" + \"\\tThe problem is in the <\".concat(tokType.name, \"> Token Type\\n\") + \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_LINE_BREAK\";\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\nexports.buildLineBreakIssueMessage = buildLineBreakIssueMessage;\nfunction getCharCodes(charsOrCodes) {\n  var charCodes = (0, map_1.default)(charsOrCodes, function (numOrString) {\n    if ((0, isString_1.default)(numOrString)) {\n      return numOrString.charCodeAt(0);\n    } else {\n      return numOrString;\n    }\n  });\n  return charCodes;\n}\nfunction addToMapOfArrays(map, key, value) {\n  if (map[key] === undefined) {\n    map[key] = [value];\n  } else {\n    map[key].push(value);\n  }\n}\nexports.minOptimizationVal = 256;\n/**\n * We are mapping charCode above ASCI (256) into buckets each in the size of 256.\n * This is because ASCI are the most common start chars so each one of those will get its own\n * possible token configs vector.\n *\n * Tokens starting with charCodes \"above\" ASCI are uncommon, so we can \"afford\"\n * to place these into buckets of possible token configs, What we gain from\n * this is avoiding the case of creating an optimization 'charCodeToPatternIdxToConfig'\n * which would contain 10,000+ arrays of small size (e.g unicode Identifiers scenario).\n * Our 'charCodeToPatternIdxToConfig' max size will now be:\n * 256 + (2^16 / 2^8) - 1 === 511\n *\n * note the hack for fast division integer part extraction\n * See: https://stackoverflow.com/a/4228528\n */\nvar charCodeToOptimizedIdxMap = [];\nfunction charCodeToOptimizedIndex(charCode) {\n  return charCode < exports.minOptimizationVal ? charCode : charCodeToOptimizedIdxMap[charCode];\n}\nexports.charCodeToOptimizedIndex = charCodeToOptimizedIndex;\n/**\n * This is a compromise between cold start / hot running performance\n * Creating this array takes ~3ms on a modern machine,\n * But if we perform the computation at runtime as needed the CSS Lexer benchmark\n * performance degrades by ~10%\n *\n * TODO: Perhaps it should be lazy initialized only if a charCode > 255 is used.\n */\nfunction initCharCodeToOptimizedIndexMap() {\n  if ((0, isEmpty_1.default)(charCodeToOptimizedIdxMap)) {\n    charCodeToOptimizedIdxMap = new Array(65536);\n    for (var i = 0; i < 65536; i++) {\n      charCodeToOptimizedIdxMap[i] = i > 255 ? 255 + ~~(i / 255) : i;\n    }\n  }\n}","map":{"version":3,"sources":["../../../src/scan/lexer.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA,IAAA,eAAA,GAAA,OAAA,CAAA,eAAA,CAAA;AACA,IAAA,cAAA,GAAA,OAAA,CAAA,gBAAA,CAAA;AACA,IAAA,OAAA,GAAA,eAAA,CAAA,OAAA,CAAA,cAAA,CAAA,CAAA;AACA,IAAA,SAAA,GAAA,eAAA,CAAA,OAAA,CAAA,gBAAA,CAAA,CAAA;AACA,IAAA,SAAA,GAAA,eAAA,CAAA,OAAA,CAAA,gBAAA,CAAA,CAAA;AACA,IAAA,SAAA,GAAA,eAAA,CAAA,OAAA,CAAA,gBAAA,CAAA,CAAA;AACA,IAAA,QAAA,GAAA,eAAA,CAAA,OAAA,CAAA,eAAA,CAAA,CAAA;AACA,IAAA,SAAA,GAAA,eAAA,CAAA,OAAA,CAAA,gBAAA,CAAA,CAAA;AACA,IAAA,QAAA,GAAA,eAAA,CAAA,OAAA,CAAA,eAAA,CAAA,CAAA;AACA,IAAA,YAAA,GAAA,eAAA,CAAA,OAAA,CAAA,mBAAA,CAAA,CAAA;AACA,IAAA,SAAA,GAAA,eAAA,CAAA,OAAA,CAAA,gBAAA,CAAA,CAAA;AACA,IAAA,KAAA,GAAA,eAAA,CAAA,OAAA,CAAA,YAAA,CAAA,CAAA;AACA,IAAA,SAAA,GAAA,eAAA,CAAA,OAAA,CAAA,gBAAA,CAAA,CAAA;AACA,IAAA,UAAA,GAAA,eAAA,CAAA,OAAA,CAAA,iBAAA,CAAA,CAAA;AACA,IAAA,YAAA,GAAA,eAAA,CAAA,OAAA,CAAA,mBAAA,CAAA,CAAA;AACA,IAAA,aAAA,GAAA,eAAA,CAAA,OAAA,CAAA,oBAAA,CAAA,CAAA;AACA,IAAA,MAAA,GAAA,eAAA,CAAA,OAAA,CAAA,aAAA,CAAA,CAAA;AACA,IAAA,KAAA,GAAA,eAAA,CAAA,OAAA,CAAA,YAAA,CAAA,CAAA;AACA,IAAA,MAAA,GAAA,eAAA,CAAA,OAAA,CAAA,aAAA,CAAA,CAAA;AACA,IAAA,UAAA,GAAA,eAAA,CAAA,OAAA,CAAA,iBAAA,CAAA,CAAA;AACA,IAAA,QAAA,GAAA,eAAA,CAAA,OAAA,CAAA,eAAA,CAAA,CAAA;AACA,IAAA,UAAA,GAAA,eAAA,CAAA,OAAA,CAAA,iBAAA,CAAA,CAAA;AACA,IAAA,QAAA,GAAA,eAAA,CAAA,OAAA,CAAA,eAAA,CAAA,CAAA;AACA,IAAA,UAAA,GAAA,eAAA,CAAA,OAAA,CAAA,iBAAA,CAAA,CAAA;AACA,IAAA,OAAA,GAAA,OAAA,CAAA,mBAAA,CAAA;AACA,IAAA,SAAA,GAAA,OAAA,CAAA,WAAA,CAAA;AAYA,IAAA,gBAAA,GAAA,OAAA,CAAA,kBAAA,CAAA;AAEA,IAAM,OAAO,GAAG,SAAS;AACZ,OAAA,CAAA,YAAY,GAAG,aAAa;AAC5B,OAAA,CAAA,KAAK,GAAG,OAAO;AAuBjB,OAAA,CAAA,cAAc,GACvB,OAAa,IAAI,MAAM,CAAC,MAAM,CAAE,CAAC,MAAM,KAAK,SAAS;AAEvD,SAAgB,aAAa,GAAA;EAC3B,OAAA,CAAA,cAAc,GAAG,KAAK;AACxB;AAFA,OAAA,CAAA,aAAA,GAAA,aAAA;AAIA,SAAgB,YAAY,GAAA;EAC1B,OAAA,CAAA,cAAc,GAAG,IAAI;AACvB;AAFA,OAAA,CAAA,YAAA,GAAA,YAAA;AAIA,SAAgB,iBAAiB,CAC/B,UAAuB,EACvB,OAQC,EAAA;EAED,OAAO,GAAG,CAAA,CAAA,EAAA,UAAA,CAAA,OAAQ,EAAC,OAAO,EAAE;IAC1B,SAAS,EAAE,OAAA,CAAA,cAAc;IACzB,KAAK,EAAE,KAAgB;IACvB,QAAQ,EAAE,KAAgB;IAC1B,gBAAgB,EAAE,MAAM;IACxB,wBAAwB,EAAE,CAAC,IAAI,EAAE,IAAI,CAAC;IACtC,MAAM,EAAE,gBAAC,GAAW,EAAE,MAAgB,EAAA;MAAK,OAAA,MAAM,EAAE;IAAR;GAC5C,CAAC;EAEF,IAAM,MAAM,GAAG,OAAO,CAAC,MAAO;EAE9B,MAAM,CAAC,iCAAiC,EAAE,YAAA;IACxC,+BAA+B,EAAE;EACnC,CAAC,CAAC;EAEF,IAAI,iBAA8B;EAClC,MAAM,CAAC,iBAAiB,EAAE,YAAA;IACxB,iBAAiB,GAAG,CAAA,CAAA,EAAA,QAAA,CAAA,OAAM,EAAC,UAAU,EAAE,UAAC,QAAQ,EAAA;MAC9C,OAAO,QAAQ,CAAC,OAAO,CAAC,KAAK,cAAA,CAAA,KAAK,CAAC,EAAE;IACvC,CAAC,CAAC;EACJ,CAAC,CAAC;EAEF,IAAI,SAAS,GAAG,KAAK;EACrB,IAAI,sBAAgD;EACpD,MAAM,CAAC,oBAAoB,EAAE,YAAA;IAC3B,SAAS,GAAG,KAAK;IACjB,sBAAsB,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAC1B,iBAAiB,EACjB,UAAC,QAAQ,EAAA;MACP,IAAM,WAAW,GAAG,QAAQ,CAAC,OAAO,CAAC;MAErC;MACA,IAAI,CAAA,CAAA,EAAA,UAAA,CAAA,OAAQ,EAAC,WAAW,CAAC,EAAE;QACzB,IAAM,YAAY,GAAG,WAAW,CAAC,MAAM;QACvC,IACE,YAAY,CAAC,MAAM,KAAK,CAAC;QACzB;QACA,YAAY,KAAK,GAAG,IACpB,YAAY,KAAK,GAAG,IACpB,YAAY,KAAK,GAAG,IACpB,CAAC,WAAW,CAAC,UAAU,EACvB;UACA,OAAO,YAAY;SACpB,MAAM,IACL,YAAY,CAAC,MAAM,KAAK,CAAC,IACzB,YAAY,CAAC,CAAC,CAAC,KAAK,IAAI;QACxB;QACA,CAAC,CAAA,CAAA,EAAA,UAAA,CAAA,OAAQ,EACP,CACE,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,CACJ,EACD,YAAY,CAAC,CAAC,CAAC,CAChB,EACD;UACA;UACA;UACA;UACA,OAAO,YAAY,CAAC,CAAC,CAAC;SACvB,MAAM;UACL,OAAO,OAAO,CAAC,SAAS,GACpB,aAAa,CAAC,WAAW,CAAC,GAC1B,eAAe,CAAC,WAAW,CAAC;QACjC;OACF,MAAM,IAAI,CAAA,CAAA,EAAA,YAAA,CAAA,OAAU,EAAC,WAAW,CAAC,EAAE;QAClC,SAAS,GAAG,IAAI;QAChB;QACA,OAAO;UAAE,IAAI,EAAE;QAAW,CAAE;OAC7B,MAAM,IAAI,OAAO,WAAW,KAAK,QAAQ,EAAE;QAC1C,SAAS,GAAG,IAAI;QAChB;QACA,OAAO,WAAW;OACnB,MAAM,IAAI,OAAO,WAAW,KAAK,QAAQ,EAAE;QAC1C,IAAI,WAAW,CAAC,MAAM,KAAK,CAAC,EAAE;UAC5B,OAAO,WAAW;SACnB,MAAM;UACL,IAAM,mBAAmB,GAAG,WAAW,CAAC,OAAO,CAC7C,qBAAqB,EACrB,MAAM,CACP;UACD,IAAM,aAAa,GAAG,IAAI,MAAM,CAAC,mBAAmB,CAAC;UACrD,OAAO,OAAO,CAAC,SAAS,GACpB,aAAa,CAAC,aAAa,CAAC,GAC5B,eAAe,CAAC,aAAa,CAAC;QACnC;OACF,MAAM;QACL,MAAM,KAAK,CAAC,sBAAsB,CAAC;MACpC;IACH,CAAC,CACF;EACH,CAAC,CAAC;EAEF,IAAI,gBAA0B;EAC9B,IAAI,iBAAiD;EACrD,IAAI,2BAAqD;EACzD,IAAI,oBAA4C;EAChD,IAAI,mBAA8B;EAClC,MAAM,CAAC,cAAc,EAAE,YAAA;IACrB,gBAAgB,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EACpB,iBAAiB,EACjB,UAAC,QAAQ,EAAA;MAAK,OAAA,QAAQ,CAAC,YAAa;IAAtB,CAAsB,CACrC;IAED,iBAAiB,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,iBAAiB,EAAE,UAAC,KAAU,EAAA;MACpD,IAAM,SAAS,GAAG,KAAK,CAAC,KAAK;MAC7B;MACA,IAAI,SAAS,KAAK,cAAA,CAAA,KAAK,CAAC,OAAO,EAAE;QAC/B,OAAO,SAAS;OACjB,MAAM,IAAI,CAAA,CAAA,EAAA,UAAA,CAAA,OAAQ,EAAC,SAAS,CAAC,EAAE;QAC9B,OAAO,SAAS;OACjB,MAAM,IAAI,CAAA,CAAA,EAAA,aAAA,CAAA,OAAW,EAAC,SAAS,CAAC,EAAE;QACjC,OAAO,KAAK;OACb,MAAM;QACL,MAAM,KAAK,CAAC,sBAAsB,CAAC;MACpC;IACH,CAAC,CAAC;IAEF,2BAA2B,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,iBAAiB,EAAE,UAAC,KAAU,EAAA;MAC9D,IAAM,aAAa,GAAG,KAAK,CAAC,UAAU;MAEtC,IAAI,aAAa,EAAE;QACjB,IAAM,eAAe,GAAG,CAAA,CAAA,EAAA,SAAA,CAAA,OAAO,EAAC,aAAa,CAAC,GAC1C,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,aAAa,EAAE,UAAC,IAAS,EAAA;UAAK,OAAA,CAAA,CAAA,EAAA,SAAA,CAAA,OAAO,EAAC,iBAAiB,EAAE,IAAI,CAAC;QAAhC,CAAgC,CAAC,GACnE,CAAC,CAAA,CAAA,EAAA,SAAA,CAAA,OAAO,EAAC,iBAAiB,EAAE,aAAa,CAAC,CAAC;QAC/C,OAAO,eAAe;MACvB;IACH,CAAC,CAAC;IAEF,oBAAoB,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EACxB,iBAAiB,EACjB,UAAC,KAAU,EAAA;MAAK,OAAA,KAAK,CAAC,SAAS;IAAf,CAAe,CAChC;IAED,mBAAmB,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,iBAAiB,EAAE,UAAC,KAAU,EAAA;MACtD,OAAA,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,KAAK,EAAE,UAAU,CAAC;IAAtB,CAAsB,CACvB;EACH,CAAC,CAAC;EAEF,IAAI,6BAAwC;EAC5C,MAAM,CAAC,0BAA0B,EAAE,YAAA;IACjC,IAAM,uBAAuB,GAAG,YAAY,CAC1C,OAAO,CAAC,wBAAyB,CAClC;IACD,6BAA6B,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,iBAAiB,EAAE,UAAC,OAAO,EAAA;MAAK,OAAA,KAAK;IAAL,CAAK,CAAC;IAC1E,IAAI,OAAO,CAAC,gBAAgB,KAAK,YAAY,EAAE;MAC7C,6BAA6B,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,iBAAiB,EAAE,UAAC,OAAO,EAAA;QAC7D,IAAI,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,OAAO,EAAE,aAAa,CAAC,EAAE;UAC/B,OAAO,CAAC,CAAC,OAAO,CAAC,WAAW;SAC7B,MAAM;UACL,OACE,qBAAqB,CAAC,OAAO,EAAE,uBAAuB,CAAC,KAAK,KAAK,IACjE,CAAA,CAAA,EAAA,SAAA,CAAA,gBAAgB,EACd,uBAAuB,EACvB,OAAO,CAAC,OAA0B,CACnC;QAEJ;MACH,CAAC,CAAC;IACH;EACH,CAAC,CAAC;EAEF,IAAI,oBAA+B;EACnC,IAAI,iBAAqC;EACzC,IAAI,WAA+C;EACnD,IAAI,kBAAqC;EACzC,MAAM,CAAC,iBAAiB,EAAE,YAAA;IACxB,oBAAoB,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,iBAAiB,EAAE,eAAe,CAAC;IAC9D,iBAAiB,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,sBAAsB,EAAE,cAAc,CAAC;IAE/D,WAAW,GAAG,CAAA,CAAA,EAAA,QAAA,CAAA,OAAM,EAClB,iBAAiB,EACjB,UAAC,GAAG,EAAE,KAAU,EAAA;MACd,IAAM,SAAS,GAAG,KAAK,CAAC,KAAK;MAC7B,IAAI,CAAA,CAAA,EAAA,UAAA,CAAA,OAAQ,EAAC,SAAS,CAAC,IAAI,EAAE,SAAS,KAAK,cAAA,CAAA,KAAK,CAAC,OAAO,CAAC,EAAE;QACzD,GAAG,CAAC,SAAS,CAAC,GAAG,EAAE;MACpB;MACD,OAAO,GAAG;IACZ,CAAC,EACD,CAAA,CAAuC,CACxC;IAED,kBAAkB,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EACtB,sBAAsB,EACtB,UAAC,CAAC,EAAE,GAAG,EAAA;MACL,OAAO;QACL,OAAO,EAAE,sBAAsB,CAAC,GAAG,CAAC;QACpC,SAAS,EAAE,2BAA2B,CAAC,GAAG,CAAC;QAC3C,iBAAiB,EAAE,6BAA6B,CAAC,GAAG,CAAC;QACrD,QAAQ,EAAE,oBAAoB,CAAC,GAAG,CAAC;QACnC,KAAK,EAAE,iBAAiB,CAAC,GAAG,CAAC;QAC7B,KAAK,EAAE,iBAAiB,CAAC,GAAG,CAAC;QAC7B,IAAI,EAAE,oBAAoB,CAAC,GAAG,CAAC;QAC/B,GAAG,EAAE,mBAAmB,CAAC,GAAG,CAAC;QAC7B,YAAY,EAAE,gBAAgB,CAAC,GAAG,CAAC;QACnC,SAAS,EAAE,iBAAiB,CAAC,GAAG;OACjC;IACH,CAAC,CACF;EACH,CAAC,CAAC;EAEF,IAAI,cAAc,GAAG,IAAI;EACzB,IAAI,4BAA4B,GAC9B,EAAE;EAEJ,IAAI,CAAC,OAAO,CAAC,QAAQ,EAAE;IACrB,MAAM,CAAC,yBAAyB,EAAE,YAAA;MAChC,4BAA4B,GAAG,CAAA,CAAA,EAAA,QAAA,CAAA,OAAM,EACnC,iBAAiB,EACjB,UAAC,MAAM,EAAE,WAAW,EAAE,GAAG,EAAA;QACvB,IAAI,OAAO,WAAW,CAAC,OAAO,KAAK,QAAQ,EAAE;UAC3C,IAAM,QAAQ,GAAG,WAAW,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC,CAAC;UAClD,IAAM,YAAY,GAAG,wBAAwB,CAAC,QAAQ,CAAC;UACvD,gBAAgB,CAAC,MAAM,EAAE,YAAY,EAAE,kBAAkB,CAAC,GAAG,CAAC,CAAC;SAChE,MAAM,IAAI,CAAA,CAAA,EAAA,SAAA,CAAA,OAAO,EAAC,WAAW,CAAC,gBAAgB,CAAC,EAAE;UAChD,IAAI,kBAAwB;UAC5B,CAAA,CAAA,EAAA,SAAA,CAAA,OAAO,EAAC,WAAW,CAAC,gBAAgB,EAAE,UAAC,SAAS,EAAA;YAC9C,IAAM,QAAQ,GACZ,OAAO,SAAS,KAAK,QAAQ,GACzB,SAAS,CAAC,UAAU,CAAC,CAAC,CAAC,GACvB,SAAS;YACf,IAAM,gBAAgB,GAAG,wBAAwB,CAAC,QAAQ,CAAC;YAC3D;YACA;YACA;YACA;YACA,IAAI,kBAAgB,KAAK,gBAAgB,EAAE;cACzC,kBAAgB,GAAG,gBAAgB;cACnC,gBAAgB,CACd,MAAM,EACN,gBAAgB,EAChB,kBAAkB,CAAC,GAAG,CAAC,CACxB;YACF;UACH,CAAC,CAAC;SACH,MAAM,IAAI,CAAA,CAAA,EAAA,UAAA,CAAA,OAAQ,EAAC,WAAW,CAAC,OAAO,CAAC,EAAE;UACxC,IAAI,WAAW,CAAC,OAAO,CAAC,OAAO,EAAE;YAC/B,cAAc,GAAG,KAAK;YACtB,IAAI,OAAO,CAAC,mBAAmB,EAAE;cAC/B,CAAA,CAAA,EAAA,OAAA,CAAA,WAAW,EACT,EAAA,CAAA,MAAA,CAAG,SAAA,CAAA,2BAA2B,CAAE,GAC9B,wBAAA,CAAA,MAAA,CAAyB,WAAW,CAAC,OAAO,CAAC,QAAQ,EAAE,EAAA,eAAA,CAAe,GACtE,sFAAsF,GACtF,6DAA6D,GAC7D,kGAAkG,CACrG;YACF;WACF,MAAM;YACL,IAAM,cAAc,GAAG,CAAA,CAAA,EAAA,SAAA,CAAA,6BAA6B,EAClD,WAAW,CAAC,OAAO,EACnB,OAAO,CAAC,mBAAmB,CAC5B;YACD;YACA;YACA;YACA,IAAI,CAAA,CAAA,EAAA,SAAA,CAAA,OAAO,EAAC,cAAc,CAAC,EAAE;cAC3B;cACA;cACA;cACA,cAAc,GAAG,KAAK;YACvB;YACD,CAAA,CAAA,EAAA,SAAA,CAAA,OAAO,EAAC,cAAc,EAAE,UAAC,IAAI,EAAA;cAC3B,gBAAgB,CAAC,MAAM,EAAE,IAAI,EAAE,kBAAkB,CAAC,GAAG,CAAC,CAAC;YACzD,CAAC,CAAC;UACH;SACF,MAAM;UACL,IAAI,OAAO,CAAC,mBAAmB,EAAE;YAC/B,CAAA,CAAA,EAAA,OAAA,CAAA,WAAW,EACT,EAAA,CAAA,MAAA,CAAG,SAAA,CAAA,2BAA2B,CAAE,GAC9B,gBAAA,CAAA,MAAA,CAAiB,WAAW,CAAC,IAAI,EAAA,qFAAA,CAAqF,GACtH,6DAA6D,GAC7D,iGAAiG,CACpG;UACF;UACD,cAAc,GAAG,KAAK;QACvB;QAED,OAAO,MAAM;MACf,CAAC,EACD,EAA8C,CAC/C;IACH,CAAC,CAAC;EACH;EAED,OAAO;IACL,WAAW,EAAE,WAAW;IACxB,kBAAkB,EAAE,kBAAkB;IACtC,4BAA4B,EAAE,4BAA4B;IAC1D,SAAS,EAAE,SAAS;IACpB,cAAc,EAAE;GACjB;AACH;AA5TA,OAAA,CAAA,iBAAA,GAAA,iBAAA;AA8TA,SAAgB,gBAAgB,CAC9B,UAAuB,EACvB,eAAyB,EAAA;EAEzB,IAAI,MAAM,GAA4B,EAAE;EAExC,IAAM,aAAa,GAAG,mBAAmB,CAAC,UAAU,CAAC;EACrD,MAAM,GAAG,MAAM,CAAC,MAAM,CAAC,aAAa,CAAC,MAAM,CAAC;EAE5C,IAAM,aAAa,GAAG,mBAAmB,CAAC,aAAa,CAAC,KAAK,CAAC;EAC9D,IAAM,eAAe,GAAG,aAAa,CAAC,KAAK;EAC3C,MAAM,GAAG,MAAM,CAAC,MAAM,CAAC,aAAa,CAAC,MAAM,CAAC;EAE5C,MAAM,GAAG,MAAM,CAAC,MAAM,CAAC,qBAAqB,CAAC,eAAe,CAAC,CAAC;EAE9D,MAAM,GAAG,MAAM,CAAC,MAAM,CAAC,oBAAoB,CAAC,eAAe,CAAC,CAAC;EAE7D,MAAM,GAAG,MAAM,CAAC,MAAM,CACpB,uBAAuB,CAAC,eAAe,EAAE,eAAe,CAAC,CAC1D;EAED,MAAM,GAAG,MAAM,CAAC,MAAM,CAAC,uBAAuB,CAAC,eAAe,CAAC,CAAC;EAEhE,OAAO,MAAM;AACf;AAxBA,OAAA,CAAA,gBAAA,GAAA,gBAAA;AA0BA,SAAS,qBAAqB,CAC5B,UAAuB,EAAA;EAEvB,IAAI,MAAM,GAA4B,EAAE;EACxC,IAAM,kBAAkB,GAAG,CAAA,CAAA,EAAA,QAAA,CAAA,OAAM,EAAC,UAAU,EAAE,UAAC,WAAW,EAAA;IACxD,OAAA,CAAA,CAAA,EAAA,UAAA,CAAA,OAAQ,EAAC,WAAW,CAAC,OAAO,CAAC,CAAC;EAA9B,CAA8B,CAC/B;EAED,MAAM,GAAG,MAAM,CAAC,MAAM,CAAC,oBAAoB,CAAC,kBAAkB,CAAC,CAAC;EAEhE,MAAM,GAAG,MAAM,CAAC,MAAM,CAAC,sBAAsB,CAAC,kBAAkB,CAAC,CAAC;EAElE,MAAM,GAAG,MAAM,CAAC,MAAM,CAAC,oBAAoB,CAAC,kBAAkB,CAAC,CAAC;EAEhE,MAAM,GAAG,MAAM,CAAC,MAAM,CAAC,qBAAqB,CAAC,kBAAkB,CAAC,CAAC;EAEjE,MAAM,GAAG,MAAM,CAAC,MAAM,CAAC,qBAAqB,CAAC,kBAAkB,CAAC,CAAC;EAEjE,OAAO,MAAM;AACf;AAOA,SAAgB,mBAAmB,CACjC,UAAuB,EAAA;EAEvB,IAAM,4BAA4B,GAAG,CAAA,CAAA,EAAA,QAAA,CAAA,OAAM,EAAC,UAAU,EAAE,UAAC,QAAQ,EAAA;IAC/D,OAAO,CAAC,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,QAAQ,EAAE,OAAO,CAAC;EAChC,CAAC,CAAC;EAEF,IAAM,MAAM,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,4BAA4B,EAAE,UAAC,QAAQ,EAAA;IACxD,OAAO;MACL,OAAO,EACL,gBAAgB,GAChB,QAAQ,CAAC,IAAI,GACb,sCAAsC;MACxC,IAAI,EAAE,cAAA,CAAA,wBAAwB,CAAC,eAAe;MAC9C,UAAU,EAAE,CAAC,QAAQ;KACtB;EACH,CAAC,CAAC;EAEF,IAAM,KAAK,GAAG,CAAA,CAAA,EAAA,YAAA,CAAA,OAAU,EAAC,UAAU,EAAE,4BAA4B,CAAC;EAClE,OAAO;IAAE,MAAM,EAAA,MAAA;IAAE,KAAK,EAAA;EAAA,CAAE;AAC1B;AApBA,OAAA,CAAA,mBAAA,GAAA,mBAAA;AAsBA,SAAgB,mBAAmB,CACjC,UAAuB,EAAA;EAEvB,IAAM,4BAA4B,GAAG,CAAA,CAAA,EAAA,QAAA,CAAA,OAAM,EAAC,UAAU,EAAE,UAAC,QAAQ,EAAA;IAC/D,IAAM,OAAO,GAAG,QAAQ,CAAC,OAAO,CAAC;IACjC,OACE,CAAC,CAAA,CAAA,EAAA,UAAA,CAAA,OAAQ,EAAC,OAAO,CAAC,IAClB,CAAC,CAAA,CAAA,EAAA,YAAA,CAAA,OAAU,EAAC,OAAO,CAAC,IACpB,CAAC,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,OAAO,EAAE,MAAM,CAAC,IACrB,CAAC,CAAA,CAAA,EAAA,UAAA,CAAA,OAAQ,EAAC,OAAO,CAAC;EAEtB,CAAC,CAAC;EAEF,IAAM,MAAM,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,4BAA4B,EAAE,UAAC,QAAQ,EAAA;IACxD,OAAO;MACL,OAAO,EACL,gBAAgB,GAChB,QAAQ,CAAC,IAAI,GACb,6CAA6C,GAC7C,8GAA8G;MAChH,IAAI,EAAE,cAAA,CAAA,wBAAwB,CAAC,eAAe;MAC9C,UAAU,EAAE,CAAC,QAAQ;KACtB;EACH,CAAC,CAAC;EAEF,IAAM,KAAK,GAAG,CAAA,CAAA,EAAA,YAAA,CAAA,OAAU,EAAC,UAAU,EAAE,4BAA4B,CAAC;EAClE,OAAO;IAAE,MAAM,EAAA,MAAA;IAAE,KAAK,EAAA;EAAA,CAAE;AAC1B;AA3BA,OAAA,CAAA,mBAAA,GAAA,mBAAA;AA6BA,IAAM,YAAY,GAAG,UAAU;AAE/B,SAAgB,oBAAoB,CAClC,UAAuB,EAAA;EAEvB,IAAA,eAAA,GAAA,aAAA,UAAA,MAAA,EAAA;IAA8B,SAAA,CAAA,eAAA,EAAA,MAAA,CAAA;IAA9B,SAAA,eAAA,GAAA;MAAA,IAAA,KAAA,GAAA,MAAA,KAAA,IAAA,IAAA,MAAA,CAAA,KAAA,CAAA,IAAA,EAAA,SAAA,CAAA,IAAA,IAAA;MACE,KAAA,CAAA,KAAK,GAAG,KAAK;;IAKf;IAHE,eAAA,CAAA,SAAA,CAAA,cAAc,GAAd,UAAe,IAAa,EAAA;MAC1B,IAAI,CAAC,KAAK,GAAG,IAAI;IACnB,CAAC;IACH,OAAA,eAAC;EAAD,CAAC,CAN6B,eAAA,CAAA,iBAAiB,CAAA;EAQ/C,IAAM,YAAY,GAAG,CAAA,CAAA,EAAA,QAAA,CAAA,OAAM,EAAC,UAAU,EAAE,UAAC,QAAQ,EAAA;IAC/C,IAAM,OAAO,GAAG,QAAQ,CAAC,OAAO;IAEhC,IAAI;MACF,IAAM,SAAS,GAAG,CAAA,CAAA,EAAA,gBAAA,CAAA,YAAY,EAAC,OAAiB,CAAC;MACjD,IAAM,gBAAgB,GAAG,IAAI,eAAe,EAAE;MAC9C,gBAAgB,CAAC,KAAK,CAAC,SAAS,CAAC;MAEjC,OAAO,gBAAgB,CAAC,KAAK;KAC9B,CAAC,OAAO,CAAC,EAAE;MACV;MACA;MACA,OAAO,YAAY,CAAC,IAAI,CAAE,OAAkB,CAAC,MAAM,CAAC;IACrD;EACH,CAAC,CAAC;EAEF,IAAM,MAAM,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,YAAY,EAAE,UAAC,QAAQ,EAAA;IACxC,OAAO;MACL,OAAO,EACL,mCAAmC,GACnC,kBAAkB,GAClB,QAAQ,CAAC,IAAI,GACb,8DAA8D,GAC9D,oEAAoE,GACpE,gBAAgB;MAClB,IAAI,EAAE,cAAA,CAAA,wBAAwB,CAAC,gBAAgB;MAC/C,UAAU,EAAE,CAAC,QAAQ;KACtB;EACH,CAAC,CAAC;EAEF,OAAO,MAAM;AACf;AA1CA,OAAA,CAAA,oBAAA,GAAA,oBAAA;AA4CA,SAAgB,qBAAqB,CACnC,UAAuB,EAAA;EAEvB,IAAM,kBAAkB,GAAG,CAAA,CAAA,EAAA,QAAA,CAAA,OAAM,EAAC,UAAU,EAAE,UAAC,QAAQ,EAAA;IACrD,IAAM,OAAO,GAAG,QAAQ,CAAC,OAAiB;IAC1C,OAAO,OAAO,CAAC,IAAI,CAAC,EAAE,CAAC;EACzB,CAAC,CAAC;EAEF,IAAM,MAAM,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,kBAAkB,EAAE,UAAC,QAAQ,EAAA;IAC9C,OAAO;MACL,OAAO,EACL,gBAAgB,GAChB,QAAQ,CAAC,IAAI,GACb,oDAAoD;MACtD,IAAI,EAAE,cAAA,CAAA,wBAAwB,CAAC,mBAAmB;MAClD,UAAU,EAAE,CAAC,QAAQ;KACtB;EACH,CAAC,CAAC;EAEF,OAAO,MAAM;AACf;AApBA,OAAA,CAAA,qBAAA,GAAA,qBAAA;AAsBA,IAAM,cAAc,GAAG,gBAAgB;AAEvC,SAAgB,sBAAsB,CACpC,UAAuB,EAAA;EAEvB,IAAA,iBAAA,GAAA,aAAA,UAAA,MAAA,EAAA;IAAgC,SAAA,CAAA,iBAAA,EAAA,MAAA,CAAA;IAAhC,SAAA,iBAAA,GAAA;MAAA,IAAA,KAAA,GAAA,MAAA,KAAA,IAAA,IAAA,MAAA,CAAA,KAAA,CAAA,IAAA,EAAA,SAAA,CAAA,IAAA,IAAA;MACE,KAAA,CAAA,KAAK,GAAG,KAAK;;IAKf;IAHE,iBAAA,CAAA,SAAA,CAAA,gBAAgB,GAAhB,UAAiB,IAAa,EAAA;MAC5B,IAAI,CAAC,KAAK,GAAG,IAAI;IACnB,CAAC;IACH,OAAA,iBAAC;EAAD,CAAC,CAN+B,eAAA,CAAA,iBAAiB,CAAA;EAQjD,IAAM,YAAY,GAAG,CAAA,CAAA,EAAA,QAAA,CAAA,OAAM,EAAC,UAAU,EAAE,UAAC,QAAQ,EAAA;IAC/C,IAAM,OAAO,GAAG,QAAQ,CAAC,OAAiB;IAC1C,IAAI;MACF,IAAM,SAAS,GAAG,CAAA,CAAA,EAAA,gBAAA,CAAA,YAAY,EAAC,OAAO,CAAC;MACvC,IAAM,kBAAkB,GAAG,IAAI,iBAAiB,EAAE;MAClD,kBAAkB,CAAC,KAAK,CAAC,SAAS,CAAC;MAEnC,OAAO,kBAAkB,CAAC,KAAK;KAChC,CAAC,OAAO,CAAC,EAAE;MACV;MACA;MACA,OAAO,cAAc,CAAC,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC;IAC3C;EACH,CAAC,CAAC;EAEF,IAAM,MAAM,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,YAAY,EAAE,UAAC,QAAQ,EAAA;IACxC,OAAO;MACL,OAAO,EACL,mCAAmC,GACnC,kBAAkB,GAClB,QAAQ,CAAC,IAAI,GACb,gEAAgE,GAChE,4EAA4E,GAC5E,gBAAgB;MAClB,IAAI,EAAE,cAAA,CAAA,wBAAwB,CAAC,gBAAgB;MAC/C,UAAU,EAAE,CAAC,QAAQ;KACtB;EACH,CAAC,CAAC;EAEF,OAAO,MAAM;AACf;AAzCA,OAAA,CAAA,sBAAA,GAAA,sBAAA;AA2CA,SAAgB,oBAAoB,CAClC,UAAuB,EAAA;EAEvB,IAAM,YAAY,GAAG,CAAA,CAAA,EAAA,QAAA,CAAA,OAAM,EAAC,UAAU,EAAE,UAAC,QAAQ,EAAA;IAC/C,IAAM,OAAO,GAAG,QAAQ,CAAC,OAAO,CAAC;IACjC,OAAO,OAAO,YAAY,MAAM,KAAK,OAAO,CAAC,SAAS,IAAI,OAAO,CAAC,MAAM,CAAC;EAC3E,CAAC,CAAC;EAEF,IAAM,MAAM,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,YAAY,EAAE,UAAC,QAAQ,EAAA;IACxC,OAAO;MACL,OAAO,EACL,gBAAgB,GAChB,QAAQ,CAAC,IAAI,GACb,mEAAmE;MACrE,IAAI,EAAE,cAAA,CAAA,wBAAwB,CAAC,uBAAuB;MACtD,UAAU,EAAE,CAAC,QAAQ;KACtB;EACH,CAAC,CAAC;EAEF,OAAO,MAAM;AACf;AApBA,OAAA,CAAA,oBAAA,GAAA,oBAAA;AAsBA;AACA,SAAgB,qBAAqB,CACnC,UAAuB,EAAA;EAEvB,IAAM,KAAK,GAAgB,EAAE;EAC7B,IAAI,iBAAiB,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,UAAU,EAAE,UAAC,SAAc,EAAA;IACrD,OAAO,CAAA,CAAA,EAAA,QAAA,CAAA,OAAM,EACX,UAAU,EACV,UAAC,MAAM,EAAE,SAAS,EAAA;MAChB,IACE,SAAS,CAAC,OAAO,CAAC,MAAM,KAAM,SAAS,CAAC,OAAkB,CAAC,MAAM,IACjE,CAAC,CAAA,CAAA,EAAA,UAAA,CAAA,OAAQ,EAAC,KAAK,EAAE,SAAS,CAAC,IAC3B,SAAS,CAAC,OAAO,KAAK,cAAA,CAAA,KAAK,CAAC,EAAE,EAC9B;QACA;QACA;QACA,KAAK,CAAC,IAAI,CAAC,SAAS,CAAC;QACrB,MAAM,CAAC,IAAI,CAAC,SAAS,CAAC;QACtB,OAAO,MAAM;MACd;MACD,OAAO,MAAM;IACf,CAAC,EACD,EAAiB,CAClB;EACH,CAAC,CAAC;EAEF,iBAAiB,GAAG,CAAA,CAAA,EAAA,SAAA,CAAA,OAAO,EAAC,iBAAiB,CAAC;EAE9C,IAAM,iBAAiB,GAAG,CAAA,CAAA,EAAA,QAAA,CAAA,OAAM,EAAC,iBAAiB,EAAE,UAAC,gBAAgB,EAAA;IACnE,OAAO,gBAAgB,CAAC,MAAM,GAAG,CAAC;EACpC,CAAC,CAAC;EAEF,IAAM,MAAM,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,iBAAiB,EAAE,UAAC,cAAmB,EAAA;IACxD,IAAM,cAAc,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,cAAc,EAAE,UAAC,QAAa,EAAA;MACvD,OAAO,QAAQ,CAAC,IAAI;IACtB,CAAC,CAAC;IAEF,IAAM,aAAa,GAAS,CAAA,CAAA,EAAA,OAAA,CAAA,OAAK,EAAC,cAAc,CAAE,CAAC,OAAO;IAC1D,OAAO;MACL,OAAO,EACL,4BAAA,CAAA,MAAA,CAA6B,aAAa,EAAA,IAAA,CAAI,GAC9C,qDAAA,CAAA,MAAA,CAAsD,cAAc,CAAC,IAAI,CACvE,IAAI,CACL,EAAA,KAAA,CAAK;MACR,IAAI,EAAE,cAAA,CAAA,wBAAwB,CAAC,wBAAwB;MACvD,UAAU,EAAE;KACb;EACH,CAAC,CAAC;EAEF,OAAO,MAAM;AACf;AAjDA,OAAA,CAAA,qBAAA,GAAA,qBAAA;AAmDA,SAAgB,oBAAoB,CAClC,UAAuB,EAAA;EAEvB,IAAM,YAAY,GAAG,CAAA,CAAA,EAAA,QAAA,CAAA,OAAM,EAAC,UAAU,EAAE,UAAC,KAAU,EAAA;IACjD,IAAI,CAAC,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,KAAK,EAAE,OAAO,CAAC,EAAE;MACxB,OAAO,KAAK;IACb;IACD,IAAM,KAAK,GAAG,KAAK,CAAC,KAAK;IAEzB,OAAO,KAAK,KAAK,cAAA,CAAA,KAAK,CAAC,OAAO,IAAI,KAAK,KAAK,cAAA,CAAA,KAAK,CAAC,EAAE,IAAI,CAAC,CAAA,CAAA,EAAA,UAAA,CAAA,OAAQ,EAAC,KAAK,CAAC;EAC1E,CAAC,CAAC;EAEF,IAAM,MAAM,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,YAAY,EAAE,UAAC,QAAQ,EAAA;IACxC,OAAO;MACL,OAAO,EACL,gBAAgB,GAChB,QAAQ,CAAC,IAAI,GACb,+DAA+D;MACjE,IAAI,EAAE,cAAA,CAAA,wBAAwB,CAAC,wBAAwB;MACvD,UAAU,EAAE,CAAC,QAAQ;KACtB;EACH,CAAC,CAAC;EAEF,OAAO,MAAM;AACf;AAxBA,OAAA,CAAA,oBAAA,GAAA,oBAAA;AA0BA,SAAgB,uBAAuB,CACrC,UAAuB,EACvB,UAAoB,EAAA;EAEpB,IAAM,YAAY,GAAG,CAAA,CAAA,EAAA,QAAA,CAAA,OAAM,EAAC,UAAU,EAAE,UAAC,KAAU,EAAA;IACjD,OACE,KAAK,CAAC,SAAS,KAAK,SAAS,IAAI,CAAC,CAAA,CAAA,EAAA,UAAA,CAAA,OAAQ,EAAC,UAAU,EAAE,KAAK,CAAC,SAAS,CAAC;EAE3E,CAAC,CAAC;EAEF,IAAM,MAAM,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,YAAY,EAAE,UAAC,OAAO,EAAA;IACvC,IAAM,GAAG,GACP,gBAAA,CAAA,MAAA,CAAiB,OAAO,CAAC,IAAI,EAAA,6DAAA,CAAA,CAAA,MAAA,CAA8D,OAAO,CAAC,SAAS,EAAA,IAAA,CAAI,GAChH,sBAAsB;IACxB,OAAO;MACL,OAAO,EAAE,GAAG;MACZ,IAAI,EAAE,cAAA,CAAA,wBAAwB,CAAC,wBAAwB;MACvD,UAAU,EAAE,CAAC,OAAO;KACrB;EACH,CAAC,CAAC;EAEF,OAAO,MAAM;AACf;AAtBA,OAAA,CAAA,uBAAA,GAAA,uBAAA;AAwBA,SAAgB,uBAAuB,CACrC,UAAuB,EAAA;EAEvB,IAAM,MAAM,GAA4B,EAAE;EAE1C,IAAM,WAAW,GAAG,CAAA,CAAA,EAAA,QAAA,CAAA,OAAM,EACxB,UAAU,EACV,UAAC,MAAM,EAAE,OAAO,EAAE,GAAG,EAAA;IACnB,IAAM,OAAO,GAAG,OAAO,CAAC,OAAO;IAE/B,IAAI,OAAO,KAAK,cAAA,CAAA,KAAK,CAAC,EAAE,EAAE;MACxB,OAAO,MAAM;IACd;IAED;IACA;IACA,IAAI,CAAA,CAAA,EAAA,UAAA,CAAA,OAAQ,EAAC,OAAO,CAAC,EAAE;MACrB,MAAM,CAAC,IAAI,CAAC;QAAE,GAAG,EAAE,OAAO;QAAE,GAAG,EAAA,GAAA;QAAE,SAAS,EAAE;MAAO,CAAE,CAAC;KACvD,MAAM,IAAI,CAAA,CAAA,EAAA,UAAA,CAAA,OAAQ,EAAC,OAAO,CAAC,IAAI,UAAU,CAAC,OAAO,CAAC,EAAE;MACnD,MAAM,CAAC,IAAI,CAAC;QAAE,GAAG,EAAE,OAAO,CAAC,MAAM;QAAE,GAAG,EAAA,GAAA;QAAE,SAAS,EAAE;MAAO,CAAE,CAAC;IAC9D;IACD,OAAO,MAAM;EACf,CAAC,EACD,EAA0D,CAC3D;EAED,CAAA,CAAA,EAAA,SAAA,CAAA,OAAO,EAAC,UAAU,EAAE,UAAC,OAAO,EAAE,OAAO,EAAA;IACnC,CAAA,CAAA,EAAA,SAAA,CAAA,OAAO,EAAC,WAAW,EAAE,UAAC,EAAuB,EAAA;UAArB,GAAG,GAAA,EAAA,CAAA,GAAA;QAAE,GAAG,GAAA,EAAA,CAAA,GAAA;QAAE,SAAS,GAAA,EAAA,CAAA,SAAA;MACzC,IAAI,OAAO,GAAG,GAAG,IAAI,aAAa,CAAC,GAAG,EAAE,OAAO,CAAC,OAAO,CAAC,EAAE;QACxD,IAAM,GAAG,GACP,WAAA,CAAA,MAAA,CAAY,SAAS,CAAC,IAAI,EAAA,4BAAA,CAA4B,GACtD,4CAAA,CAAA,MAAA,CAA6C,OAAO,CAAC,IAAI,EAAA,IAAA,CAAI,GAC7D,8BAA8B,GAC9B,8EAA8E;QAChF,MAAM,CAAC,IAAI,CAAC;UACV,OAAO,EAAE,GAAG;UACZ,IAAI,EAAE,cAAA,CAAA,wBAAwB,CAAC,mBAAmB;UAClD,UAAU,EAAE,CAAC,OAAO,EAAE,SAAS;SAChC,CAAC;MACH;IACH,CAAC,CAAC;EACJ,CAAC,CAAC;EAEF,OAAO,MAAM;AACf;AA5CA,OAAA,CAAA,uBAAA,GAAA,uBAAA;AA8CA,SAAS,aAAa,CAAC,GAAW,EAAE,OAAY,EAAA;EAC9C;EACA,IAAI,CAAA,CAAA,EAAA,UAAA,CAAA,OAAQ,EAAC,OAAO,CAAC,EAAE;IACrB,IAAM,WAAW,GAAG,OAAO,CAAC,IAAI,CAAC,GAAG,CAAC;IACrC,OAAO,WAAW,KAAK,IAAI,IAAI,WAAW,CAAC,KAAK,KAAK,CAAC;GACvD,MAAM,IAAI,CAAA,CAAA,EAAA,YAAA,CAAA,OAAU,EAAC,OAAO,CAAC,EAAE;IAC9B;IACA,OAAO,OAAO,CAAC,GAAG,EAAE,CAAC,EAAE,EAAE,EAAE,CAAA,CAAE,CAAC;GAC/B,MAAM,IAAI,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,OAAO,EAAE,MAAM,CAAC,EAAE;IAC/B;IACA,OAAO,OAAO,CAAC,IAAI,CAAC,GAAG,EAAE,CAAC,EAAE,EAAE,EAAE,CAAA,CAAE,CAAC;GACpC,MAAM,IAAI,OAAO,OAAO,KAAK,QAAQ,EAAE;IACtC,OAAO,OAAO,KAAK,GAAG;GACvB,MAAM;IACL,MAAM,KAAK,CAAC,sBAAsB,CAAC;EACpC;AACH;AAEA,SAAS,UAAU,CAAC,MAAc,EAAA;EAChC;EACA,IAAM,SAAS,GAAG,CAChB,GAAG,EACH,IAAI,EACJ,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,EACH,GAAG,CACJ;EACD,OACE,CAAA,CAAA,EAAA,MAAA,CAAA,OAAI,EAAC,SAAS,EAAE,UAAC,IAAI,EAAA;IAAK,OAAA,MAAM,CAAC,MAAM,CAAC,OAAO,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;EAAlC,CAAkC,CAAC,KAAK,SAAS;AAE/E;AAEA,SAAgB,eAAe,CAAC,OAAe,EAAA;EAC7C,IAAM,KAAK,GAAG,OAAO,CAAC,UAAU,GAAG,GAAG,GAAG,EAAE;EAC3C;EACA;EACA,OAAO,IAAI,MAAM,CAAC,MAAA,CAAA,MAAA,CAAO,OAAO,CAAC,MAAM,EAAA,GAAA,CAAG,EAAE,KAAK,CAAC;AACpD;AALA,OAAA,CAAA,eAAA,GAAA,eAAA;AAOA,SAAgB,aAAa,CAAC,OAAe,EAAA;EAC3C,IAAM,KAAK,GAAG,OAAO,CAAC,UAAU,GAAG,IAAI,GAAG,GAAG;EAC7C;EACA;EACA,OAAO,IAAI,MAAM,CAAC,EAAA,CAAA,MAAA,CAAG,OAAO,CAAC,MAAM,CAAE,EAAE,KAAK,CAAC;AAC/C;AALA,OAAA,CAAA,aAAA,GAAA,aAAA;AAOA,SAAgB,oBAAoB,CAClC,eAA0C,EAC1C,UAAmB,EACnB,wBAA6C,EAAA;EAE7C,IAAM,MAAM,GAA4B,EAAE;EAE1C;EACA,IAAI,CAAC,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,eAAe,EAAE,OAAA,CAAA,YAAY,CAAC,EAAE;IACvC,MAAM,CAAC,IAAI,CAAC;MACV,OAAO,EACL,qDAAqD,GACrD,OAAA,CAAA,YAAY,GACZ,gCAAgC;MAClC,IAAI,EAAE,cAAA,CAAA,wBAAwB,CAAC;KAChC,CAAC;EACH;EACD,IAAI,CAAC,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,eAAe,EAAE,OAAA,CAAA,KAAK,CAAC,EAAE;IAChC,MAAM,CAAC,IAAI,CAAC;MACV,OAAO,EACL,qDAAqD,GACrD,OAAA,CAAA,KAAK,GACL,gCAAgC;MAClC,IAAI,EAAE,cAAA,CAAA,wBAAwB,CAAC;KAChC,CAAC;EACH;EAED,IACE,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,eAAe,EAAE,OAAA,CAAA,KAAK,CAAC,IAC3B,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,eAAe,EAAE,OAAA,CAAA,YAAY,CAAC,IAClC,CAAC,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,eAAe,CAAC,KAAK,EAAE,eAAe,CAAC,WAAW,CAAC,EACxD;IACA,MAAM,CAAC,IAAI,CAAC;MACV,OAAO,EACL,iDAAA,CAAA,MAAA,CAAkD,OAAA,CAAA,YAAY,EAAA,KAAA,CAAA,CAAA,MAAA,CAAM,eAAe,CAAC,WAAW,EAAA,GAAA,CAAG,GAClG,wBAAwB;MAC1B,IAAI,EAAE,cAAA,CAAA,wBAAwB,CAAC;KAChC,CAAC;EACH;EAED,IAAI,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,eAAe,EAAE,OAAA,CAAA,KAAK,CAAC,EAAE;IAC/B,CAAA,CAAA,EAAA,SAAA,CAAA,OAAO,EAAC,eAAe,CAAC,KAAK,EAAE,UAAC,aAAa,EAAE,YAAY,EAAA;MACzD,CAAA,CAAA,EAAA,SAAA,CAAA,OAAO,EAAC,aAAa,EAAE,UAAC,WAAW,EAAE,OAAO,EAAA;QAC1C,IAAI,CAAA,CAAA,EAAA,aAAA,CAAA,OAAW,EAAC,WAAW,CAAC,EAAE;UAC5B,MAAM,CAAC,IAAI,CAAC;YACV,OAAO,EACL,oEAAoE,GACpE,GAAA,CAAA,MAAA,CAAI,YAAY,EAAA,eAAA,CAAA,CAAA,MAAA,CAAgB,OAAO,EAAA,KAAA,CAAK;YAC9C,IAAI,EAAE,cAAA,CAAA,wBAAwB,CAAC;WAChC,CAAC;SACH,MAAM,IAAI,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,WAAW,EAAE,YAAY,CAAC,EAAE;UACzC,IAAM,SAAS,GAAG,CAAA,CAAA,EAAA,SAAA,CAAA,OAAO,EAAC,WAAW,CAAC,UAAU,CAAC,GAC7C,WAAW,CAAC,UAAU,GACtB,CAAC,WAAW,CAAC,UAAU,CAAC;UAC5B,CAAA,CAAA,EAAA,SAAA,CAAA,OAAO,EAAC,SAAS,EAAE,UAAC,aAAa,EAAA;YAC/B,IACE,CAAC,CAAA,CAAA,EAAA,aAAA,CAAA,OAAW,EAAC,aAAa,CAAC,IAC3B,CAAC,CAAA,CAAA,EAAA,UAAA,CAAA,OAAQ,EAAC,aAAa,EAAE,aAAa,CAAC,EACvC;cACA,MAAM,CAAC,IAAI,CAAC;gBACV,OAAO,EAAE,6DAAA,CAAA,MAAA,CAA8D,aAAa,CAAC,IAAI,EAAA,cAAA,CAAA,CAAA,MAAA,CAAe,WAAW,CAAC,IAAI,EAAA,qBAAA,CAAA,CAAA,MAAA,CAAsB,YAAY,EAAA,KAAA,CAAK;gBAC/J,IAAI,EAAE,cAAA,CAAA,wBAAwB,CAAC;eAChC,CAAC;YACH;UACH,CAAC,CAAC;QACH;MACH,CAAC,CAAC;IACJ,CAAC,CAAC;EACH;EAED,OAAO,MAAM;AACf;AAvEA,OAAA,CAAA,oBAAA,GAAA,oBAAA;AAyEA,SAAgB,2BAA2B,CACzC,eAA0C,EAC1C,UAAmB,EACnB,wBAA6C,EAAA;EAE7C,IAAM,QAAQ,GAAG,EAAE;EACnB,IAAI,eAAe,GAAG,KAAK;EAC3B,IAAM,aAAa,GAAG,CAAA,CAAA,EAAA,SAAA,CAAA,OAAO,EAAC,CAAA,CAAA,EAAA,SAAA,CAAA,OAAO,EAAC,CAAA,CAAA,EAAA,QAAA,CAAA,OAAM,EAAC,eAAe,CAAC,KAAK,CAAC,CAAC,CAAC;EAErE,IAAM,kBAAkB,GAAG,CAAA,CAAA,EAAA,QAAA,CAAA,OAAM,EAC/B,aAAa,EACb,UAAC,QAAQ,EAAA;IAAK,OAAA,QAAQ,CAAC,OAAO,CAAC,KAAK,cAAA,CAAA,KAAK,CAAC,EAAE;EAA9B,CAA8B,CAC7C;EACD,IAAM,mBAAmB,GAAG,YAAY,CAAC,wBAAwB,CAAC;EAClE,IAAI,UAAU,EAAE;IACd,CAAA,CAAA,EAAA,SAAA,CAAA,OAAO,EAAC,kBAAkB,EAAE,UAAC,OAAO,EAAA;MAClC,IAAM,SAAS,GAAG,qBAAqB,CAAC,OAAO,EAAE,mBAAmB,CAAC;MACrE,IAAI,SAAS,KAAK,KAAK,EAAE;QACvB,IAAM,OAAO,GAAG,0BAA0B,CAAC,OAAO,EAAE,SAAS,CAAC;QAC9D,IAAM,iBAAiB,GAAG;UACxB,OAAO,EAAA,OAAA;UACP,IAAI,EAAE,SAAS,CAAC,KAAK;UACrB,SAAS,EAAE;SACZ;QACD,QAAQ,CAAC,IAAI,CAAC,iBAAiB,CAAC;OACjC,MAAM;QACL;QACA,IAAI,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,OAAO,EAAE,aAAa,CAAC,EAAE;UAC/B,IAAI,OAAO,CAAC,WAAW,KAAK,IAAI,EAAE;YAChC,eAAe,GAAG,IAAI;UACvB;SACF,MAAM;UACL,IACE,CAAA,CAAA,EAAA,SAAA,CAAA,gBAAgB,EAAC,mBAAmB,EAAE,OAAO,CAAC,OAAiB,CAAC,EAChE;YACA,eAAe,GAAG,IAAI;UACvB;QACF;MACF;IACH,CAAC,CAAC;EACH;EAED,IAAI,UAAU,IAAI,CAAC,eAAe,EAAE;IAClC,QAAQ,CAAC,IAAI,CAAC;MACZ,OAAO,EACL,kCAAkC,GAClC,uEAAuE,GACvE,kFAAkF,GAClF,mFAAmF,GACnF,gBAAgB;MAClB,IAAI,EAAE,cAAA,CAAA,wBAAwB,CAAC;KAChC,CAAC;EACH;EACD,OAAO,QAAQ;AACjB;AAtDA,OAAA,CAAA,2BAAA,GAAA,2BAAA;AAwDA,SAAgB,gBAAgB,CAAC,WAEhC,EAAA;EACC,IAAM,YAAY,GAAQ,CAAA,CAAE;EAC5B,IAAM,SAAS,GAAG,CAAA,CAAA,EAAA,MAAA,CAAA,OAAI,EAAC,WAAW,CAAC;EAEnC,CAAA,CAAA,EAAA,SAAA,CAAA,OAAO,EAAC,SAAS,EAAE,UAAC,OAAO,EAAA;IACzB,IAAM,cAAc,GAAG,WAAW,CAAC,OAAO,CAAC;IAE3C;IACA,IAAI,CAAA,CAAA,EAAA,SAAA,CAAA,OAAO,EAAC,cAAc,CAAC,EAAE;MAC3B,YAAY,CAAC,OAAO,CAAC,GAAG,EAAE;KAC3B,MAAM;MACL,MAAM,KAAK,CAAC,sBAAsB,CAAC;IACpC;EACH,CAAC,CAAC;EAEF,OAAO,YAAY;AACrB;AAlBA,OAAA,CAAA,gBAAA,GAAA,gBAAA;AAoBA;AACA,SAAgB,eAAe,CAAC,SAAoB,EAAA;EAClD,IAAM,OAAO,GAAG,SAAS,CAAC,OAAO;EACjC;EACA,IAAI,CAAA,CAAA,EAAA,UAAA,CAAA,OAAQ,EAAC,OAAO,CAAC,EAAE;IACrB,OAAO,KAAK;GACb,MAAM,IAAI,CAAA,CAAA,EAAA,YAAA,CAAA,OAAU,EAAC,OAAO,CAAC,EAAE;IAC9B;IACA,OAAO,IAAI;GACZ,MAAM,IAAI,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,OAAO,EAAE,MAAM,CAAC,EAAE;IAC/B;IACA,OAAO,IAAI;GACZ,MAAM,IAAI,CAAA,CAAA,EAAA,UAAA,CAAA,OAAQ,EAAC,OAAO,CAAC,EAAE;IAC5B,OAAO,KAAK;GACb,MAAM;IACL,MAAM,KAAK,CAAC,sBAAsB,CAAC;EACpC;AACH;AAhBA,OAAA,CAAA,eAAA,GAAA,eAAA;AAkBA,SAAgB,cAAc,CAAC,OAAY,EAAA;EACzC,IAAI,CAAA,CAAA,EAAA,UAAA,CAAA,OAAQ,EAAC,OAAO,CAAC,IAAI,OAAO,CAAC,MAAM,KAAK,CAAC,EAAE;IAC7C,OAAO,OAAO,CAAC,UAAU,CAAC,CAAC,CAAC;GAC7B,MAAM;IACL,OAAO,KAAK;EACb;AACH;AANA,OAAA,CAAA,cAAA,GAAA,cAAA;AAQA;;AAEG;AACU,OAAA,CAAA,6BAA6B,GAA2B;EACnE;EACA,IAAI,EAAE,cAAU,IAAI,EAAA;IAClB,IAAM,GAAG,GAAG,IAAI,CAAC,MAAM;IACvB,KAAK,IAAI,CAAC,GAAG,IAAI,CAAC,SAAS,EAAE,CAAC,GAAG,GAAG,EAAE,CAAC,EAAE,EAAE;MACzC,IAAM,CAAC,GAAG,IAAI,CAAC,UAAU,CAAC,CAAC,CAAC;MAC5B,IAAI,CAAC,KAAK,EAAE,EAAE;QACZ,IAAI,CAAC,SAAS,GAAG,CAAC,GAAG,CAAC;QACtB,OAAO,IAAI;OACZ,MAAM,IAAI,CAAC,KAAK,EAAE,EAAE;QACnB,IAAI,IAAI,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK,EAAE,EAAE;UACjC,IAAI,CAAC,SAAS,GAAG,CAAC,GAAG,CAAC;SACvB,MAAM;UACL,IAAI,CAAC,SAAS,GAAG,CAAC,GAAG,CAAC;QACvB;QACD,OAAO,IAAI;MACZ;IACF;IACD,OAAO,KAAK;EACd,CAAC;EAED,SAAS,EAAE;CACZ;AAED,SAAS,qBAAqB,CAC5B,OAAkB,EAClB,uBAAiC,EAAA;EASjC,IAAI,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,OAAO,EAAE,aAAa,CAAC,EAAE;IAC/B;IACA;IACA,OAAO,KAAK;GACb,MAAM;IACL;IACA,IAAI,CAAA,CAAA,EAAA,UAAA,CAAA,OAAQ,EAAC,OAAO,CAAC,OAAO,CAAC,EAAE;MAC7B,IAAI;QACF;QACA,CAAA,CAAA,EAAA,SAAA,CAAA,gBAAgB,EAAC,uBAAuB,EAAE,OAAO,CAAC,OAAiB,CAAC;OACrE,CAAC,OAAO,CAAC,EAAE;QACV;QACA,OAAO;UACL,KAAK,EAAE,cAAA,CAAA,wBAAwB,CAAC,mBAAmB;UACnD,MAAM,EAAG,CAAW,CAAC;SACtB;MACF;MACD,OAAO,KAAK;KACb,MAAM,IAAI,CAAA,CAAA,EAAA,UAAA,CAAA,OAAQ,EAAC,OAAO,CAAC,OAAO,CAAC,EAAE;MACpC;MACA,OAAO,KAAK;KACb,MAAM,IAAI,eAAe,CAAC,OAAO,CAAC,EAAE;MACnC;MACA,OAAO;QAAE,KAAK,EAAE,cAAA,CAAA,wBAAwB,CAAC;MAAiB,CAAE;KAC7D,MAAM;MACL,MAAM,KAAK,CAAC,sBAAsB,CAAC;IACpC;EACF;AACH;AAEA,SAAgB,0BAA0B,CACxC,OAAkB,EAClB,OAKC,EAAA;EAED;EACA,IAAI,OAAO,CAAC,KAAK,KAAK,cAAA,CAAA,wBAAwB,CAAC,mBAAmB,EAAE;IAClE,OACE,iEAAiE,GACjE,2BAAA,CAAA,MAAA,CAA4B,OAAO,CAAC,IAAI,EAAA,gBAAA,CAAgB,GACxD,iBAAA,CAAA,MAAA,CAAkB,OAAO,CAAC,MAAM,EAAA,KAAA,CAAK,GACrC,qGAAqG;GAExG,MAAM,IAAI,OAAO,CAAC,KAAK,KAAK,cAAA,CAAA,wBAAwB,CAAC,iBAAiB,EAAE;IACvE,OACE,4EAA4E,GAC5E,2BAAA,CAAA,MAAA,CAA4B,OAAO,CAAC,IAAI,EAAA,gBAAA,CAAgB,GACxD,mGAAmG;GAEtG,MAAM;IACL,MAAM,KAAK,CAAC,sBAAsB,CAAC;EACpC;AACH;AA1BA,OAAA,CAAA,0BAAA,GAAA,0BAAA;AA4BA,SAAS,YAAY,CAAC,YAAiC,EAAA;EACrD,IAAM,SAAS,GAAG,CAAA,CAAA,EAAA,KAAA,CAAA,OAAG,EAAC,YAAY,EAAE,UAAC,WAAW,EAAA;IAC9C,IAAI,CAAA,CAAA,EAAA,UAAA,CAAA,OAAQ,EAAC,WAAW,CAAC,EAAE;MACzB,OAAO,WAAW,CAAC,UAAU,CAAC,CAAC,CAAC;KACjC,MAAM;MACL,OAAO,WAAW;IACnB;EACH,CAAC,CAAC;EAEF,OAAO,SAAS;AAClB;AAEA,SAAS,gBAAgB,CACvB,GAAwB,EACxB,GAAW,EACX,KAAQ,EAAA;EAER,IAAI,GAAG,CAAC,GAAG,CAAC,KAAK,SAAS,EAAE;IAC1B,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,KAAK,CAAC;GACnB,MAAM;IACL,GAAG,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC;EACrB;AACH;AAEa,OAAA,CAAA,kBAAkB,GAAG,GAAG;AAErC;;;;;;;;;;;;;;AAcG;AACH,IAAI,yBAAyB,GAAa,EAAE;AAC5C,SAAgB,wBAAwB,CAAC,QAAgB,EAAA;EACvD,OAAO,QAAQ,GAAG,OAAA,CAAA,kBAAkB,GAChC,QAAQ,GACR,yBAAyB,CAAC,QAAQ,CAAC;AACzC;AAJA,OAAA,CAAA,wBAAA,GAAA,wBAAA;AAMA;;;;;;;AAOG;AACH,SAAS,+BAA+B,GAAA;EACtC,IAAI,CAAA,CAAA,EAAA,SAAA,CAAA,OAAO,EAAC,yBAAyB,CAAC,EAAE;IACtC,yBAAyB,GAAG,IAAI,KAAK,CAAC,KAAK,CAAC;IAC5C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,EAAE,CAAC,EAAE,EAAE;MAC9B,yBAAyB,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,CAAC,EAAE,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC;IAC/D;EACF;AACH","sourceRoot":"","sourcesContent":["\"use strict\";\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        if (typeof b !== \"function\" && b !== null)\n            throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.charCodeToOptimizedIndex = exports.minOptimizationVal = exports.buildLineBreakIssueMessage = exports.LineTerminatorOptimizedTester = exports.isShortPattern = exports.isCustomPattern = exports.cloneEmptyGroups = exports.performWarningRuntimeChecks = exports.performRuntimeChecks = exports.addStickyFlag = exports.addStartOfInput = exports.findUnreachablePatterns = exports.findModesThatDoNotExist = exports.findInvalidGroupType = exports.findDuplicatePatterns = exports.findUnsupportedFlags = exports.findStartOfInputAnchor = exports.findEmptyMatchRegExps = exports.findEndOfInputAnchor = exports.findInvalidPatterns = exports.findMissingPatterns = exports.validatePatterns = exports.analyzeTokenTypes = exports.enableSticky = exports.disableSticky = exports.SUPPORT_STICKY = exports.MODES = exports.DEFAULT_MODE = void 0;\nvar regexp_to_ast_1 = require(\"regexp-to-ast\");\nvar lexer_public_1 = require(\"./lexer_public\");\nvar first_1 = __importDefault(require(\"lodash/first\"));\nvar isEmpty_1 = __importDefault(require(\"lodash/isEmpty\"));\nvar compact_1 = __importDefault(require(\"lodash/compact\"));\nvar isArray_1 = __importDefault(require(\"lodash/isArray\"));\nvar values_1 = __importDefault(require(\"lodash/values\"));\nvar flatten_1 = __importDefault(require(\"lodash/flatten\"));\nvar reject_1 = __importDefault(require(\"lodash/reject\"));\nvar difference_1 = __importDefault(require(\"lodash/difference\"));\nvar indexOf_1 = __importDefault(require(\"lodash/indexOf\"));\nvar map_1 = __importDefault(require(\"lodash/map\"));\nvar forEach_1 = __importDefault(require(\"lodash/forEach\"));\nvar isString_1 = __importDefault(require(\"lodash/isString\"));\nvar isFunction_1 = __importDefault(require(\"lodash/isFunction\"));\nvar isUndefined_1 = __importDefault(require(\"lodash/isUndefined\"));\nvar find_1 = __importDefault(require(\"lodash/find\"));\nvar has_1 = __importDefault(require(\"lodash/has\"));\nvar keys_1 = __importDefault(require(\"lodash/keys\"));\nvar isRegExp_1 = __importDefault(require(\"lodash/isRegExp\"));\nvar filter_1 = __importDefault(require(\"lodash/filter\"));\nvar defaults_1 = __importDefault(require(\"lodash/defaults\"));\nvar reduce_1 = __importDefault(require(\"lodash/reduce\"));\nvar includes_1 = __importDefault(require(\"lodash/includes\"));\nvar utils_1 = require(\"@chevrotain/utils\");\nvar reg_exp_1 = require(\"./reg_exp\");\nvar reg_exp_parser_1 = require(\"./reg_exp_parser\");\nvar PATTERN = \"PATTERN\";\nexports.DEFAULT_MODE = \"defaultMode\";\nexports.MODES = \"modes\";\nexports.SUPPORT_STICKY = typeof new RegExp(\"(?:)\").sticky === \"boolean\";\nfunction disableSticky() {\n    exports.SUPPORT_STICKY = false;\n}\nexports.disableSticky = disableSticky;\nfunction enableSticky() {\n    exports.SUPPORT_STICKY = true;\n}\nexports.enableSticky = enableSticky;\nfunction analyzeTokenTypes(tokenTypes, options) {\n    options = (0, defaults_1.default)(options, {\n        useSticky: exports.SUPPORT_STICKY,\n        debug: false,\n        safeMode: false,\n        positionTracking: \"full\",\n        lineTerminatorCharacters: [\"\\r\", \"\\n\"],\n        tracer: function (msg, action) { return action(); }\n    });\n    var tracer = options.tracer;\n    tracer(\"initCharCodeToOptimizedIndexMap\", function () {\n        initCharCodeToOptimizedIndexMap();\n    });\n    var onlyRelevantTypes;\n    tracer(\"Reject Lexer.NA\", function () {\n        onlyRelevantTypes = (0, reject_1.default)(tokenTypes, function (currType) {\n            return currType[PATTERN] === lexer_public_1.Lexer.NA;\n        });\n    });\n    var hasCustom = false;\n    var allTransformedPatterns;\n    tracer(\"Transform Patterns\", function () {\n        hasCustom = false;\n        allTransformedPatterns = (0, map_1.default)(onlyRelevantTypes, function (currType) {\n            var currPattern = currType[PATTERN];\n            /* istanbul ignore else */\n            if ((0, isRegExp_1.default)(currPattern)) {\n                var regExpSource = currPattern.source;\n                if (regExpSource.length === 1 &&\n                    // only these regExp meta characters which can appear in a length one regExp\n                    regExpSource !== \"^\" &&\n                    regExpSource !== \"$\" &&\n                    regExpSource !== \".\" &&\n                    !currPattern.ignoreCase) {\n                    return regExpSource;\n                }\n                else if (regExpSource.length === 2 &&\n                    regExpSource[0] === \"\\\\\" &&\n                    // not a meta character\n                    !(0, includes_1.default)([\n                        \"d\",\n                        \"D\",\n                        \"s\",\n                        \"S\",\n                        \"t\",\n                        \"r\",\n                        \"n\",\n                        \"t\",\n                        \"0\",\n                        \"c\",\n                        \"b\",\n                        \"B\",\n                        \"f\",\n                        \"v\",\n                        \"w\",\n                        \"W\"\n                    ], regExpSource[1])) {\n                    // escaped meta Characters: /\\+/ /\\[/\n                    // or redundant escaping: /\\a/\n                    // without the escaping \"\\\"\n                    return regExpSource[1];\n                }\n                else {\n                    return options.useSticky\n                        ? addStickyFlag(currPattern)\n                        : addStartOfInput(currPattern);\n                }\n            }\n            else if ((0, isFunction_1.default)(currPattern)) {\n                hasCustom = true;\n                // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n                return { exec: currPattern };\n            }\n            else if (typeof currPattern === \"object\") {\n                hasCustom = true;\n                // ICustomPattern\n                return currPattern;\n            }\n            else if (typeof currPattern === \"string\") {\n                if (currPattern.length === 1) {\n                    return currPattern;\n                }\n                else {\n                    var escapedRegExpString = currPattern.replace(/[\\\\^$.*+?()[\\]{}|]/g, \"\\\\$&\");\n                    var wrappedRegExp = new RegExp(escapedRegExpString);\n                    return options.useSticky\n                        ? addStickyFlag(wrappedRegExp)\n                        : addStartOfInput(wrappedRegExp);\n                }\n            }\n            else {\n                throw Error(\"non exhaustive match\");\n            }\n        });\n    });\n    var patternIdxToType;\n    var patternIdxToGroup;\n    var patternIdxToLongerAltIdxArr;\n    var patternIdxToPushMode;\n    var patternIdxToPopMode;\n    tracer(\"misc mapping\", function () {\n        patternIdxToType = (0, map_1.default)(onlyRelevantTypes, function (currType) { return currType.tokenTypeIdx; });\n        patternIdxToGroup = (0, map_1.default)(onlyRelevantTypes, function (clazz) {\n            var groupName = clazz.GROUP;\n            /* istanbul ignore next */\n            if (groupName === lexer_public_1.Lexer.SKIPPED) {\n                return undefined;\n            }\n            else if ((0, isString_1.default)(groupName)) {\n                return groupName;\n            }\n            else if ((0, isUndefined_1.default)(groupName)) {\n                return false;\n            }\n            else {\n                throw Error(\"non exhaustive match\");\n            }\n        });\n        patternIdxToLongerAltIdxArr = (0, map_1.default)(onlyRelevantTypes, function (clazz) {\n            var longerAltType = clazz.LONGER_ALT;\n            if (longerAltType) {\n                var longerAltIdxArr = (0, isArray_1.default)(longerAltType)\n                    ? (0, map_1.default)(longerAltType, function (type) { return (0, indexOf_1.default)(onlyRelevantTypes, type); })\n                    : [(0, indexOf_1.default)(onlyRelevantTypes, longerAltType)];\n                return longerAltIdxArr;\n            }\n        });\n        patternIdxToPushMode = (0, map_1.default)(onlyRelevantTypes, function (clazz) { return clazz.PUSH_MODE; });\n        patternIdxToPopMode = (0, map_1.default)(onlyRelevantTypes, function (clazz) {\n            return (0, has_1.default)(clazz, \"POP_MODE\");\n        });\n    });\n    var patternIdxToCanLineTerminator;\n    tracer(\"Line Terminator Handling\", function () {\n        var lineTerminatorCharCodes = getCharCodes(options.lineTerminatorCharacters);\n        patternIdxToCanLineTerminator = (0, map_1.default)(onlyRelevantTypes, function (tokType) { return false; });\n        if (options.positionTracking !== \"onlyOffset\") {\n            patternIdxToCanLineTerminator = (0, map_1.default)(onlyRelevantTypes, function (tokType) {\n                if ((0, has_1.default)(tokType, \"LINE_BREAKS\")) {\n                    return !!tokType.LINE_BREAKS;\n                }\n                else {\n                    return (checkLineBreaksIssues(tokType, lineTerminatorCharCodes) === false &&\n                        (0, reg_exp_1.canMatchCharCode)(lineTerminatorCharCodes, tokType.PATTERN));\n                }\n            });\n        }\n    });\n    var patternIdxToIsCustom;\n    var patternIdxToShort;\n    var emptyGroups;\n    var patternIdxToConfig;\n    tracer(\"Misc Mapping #2\", function () {\n        patternIdxToIsCustom = (0, map_1.default)(onlyRelevantTypes, isCustomPattern);\n        patternIdxToShort = (0, map_1.default)(allTransformedPatterns, isShortPattern);\n        emptyGroups = (0, reduce_1.default)(onlyRelevantTypes, function (acc, clazz) {\n            var groupName = clazz.GROUP;\n            if ((0, isString_1.default)(groupName) && !(groupName === lexer_public_1.Lexer.SKIPPED)) {\n                acc[groupName] = [];\n            }\n            return acc;\n        }, {});\n        patternIdxToConfig = (0, map_1.default)(allTransformedPatterns, function (x, idx) {\n            return {\n                pattern: allTransformedPatterns[idx],\n                longerAlt: patternIdxToLongerAltIdxArr[idx],\n                canLineTerminator: patternIdxToCanLineTerminator[idx],\n                isCustom: patternIdxToIsCustom[idx],\n                short: patternIdxToShort[idx],\n                group: patternIdxToGroup[idx],\n                push: patternIdxToPushMode[idx],\n                pop: patternIdxToPopMode[idx],\n                tokenTypeIdx: patternIdxToType[idx],\n                tokenType: onlyRelevantTypes[idx]\n            };\n        });\n    });\n    var canBeOptimized = true;\n    var charCodeToPatternIdxToConfig = [];\n    if (!options.safeMode) {\n        tracer(\"First Char Optimization\", function () {\n            charCodeToPatternIdxToConfig = (0, reduce_1.default)(onlyRelevantTypes, function (result, currTokType, idx) {\n                if (typeof currTokType.PATTERN === \"string\") {\n                    var charCode = currTokType.PATTERN.charCodeAt(0);\n                    var optimizedIdx = charCodeToOptimizedIndex(charCode);\n                    addToMapOfArrays(result, optimizedIdx, patternIdxToConfig[idx]);\n                }\n                else if ((0, isArray_1.default)(currTokType.START_CHARS_HINT)) {\n                    var lastOptimizedIdx_1;\n                    (0, forEach_1.default)(currTokType.START_CHARS_HINT, function (charOrInt) {\n                        var charCode = typeof charOrInt === \"string\"\n                            ? charOrInt.charCodeAt(0)\n                            : charOrInt;\n                        var currOptimizedIdx = charCodeToOptimizedIndex(charCode);\n                        // Avoid adding the config multiple times\n                        /* istanbul ignore else */\n                        // - Difficult to check this scenario effects as it is only a performance\n                        //   optimization that does not change correctness\n                        if (lastOptimizedIdx_1 !== currOptimizedIdx) {\n                            lastOptimizedIdx_1 = currOptimizedIdx;\n                            addToMapOfArrays(result, currOptimizedIdx, patternIdxToConfig[idx]);\n                        }\n                    });\n                }\n                else if ((0, isRegExp_1.default)(currTokType.PATTERN)) {\n                    if (currTokType.PATTERN.unicode) {\n                        canBeOptimized = false;\n                        if (options.ensureOptimizations) {\n                            (0, utils_1.PRINT_ERROR)(\"\".concat(reg_exp_1.failedOptimizationPrefixMsg) +\n                                \"\\tUnable to analyze < \".concat(currTokType.PATTERN.toString(), \" > pattern.\\n\") +\n                                \"\\tThe regexp unicode flag is not currently supported by the regexp-to-ast library.\\n\" +\n                                \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                                \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNICODE_OPTIMIZE\");\n                        }\n                    }\n                    else {\n                        var optimizedCodes = (0, reg_exp_1.getOptimizedStartCodesIndices)(currTokType.PATTERN, options.ensureOptimizations);\n                        /* istanbul ignore if */\n                        // start code will only be empty given an empty regExp or failure of regexp-to-ast library\n                        // the first should be a different validation and the second cannot be tested.\n                        if ((0, isEmpty_1.default)(optimizedCodes)) {\n                            // we cannot understand what codes may start possible matches\n                            // The optimization correctness requires knowing start codes for ALL patterns.\n                            // Not actually sure this is an error, no debug message\n                            canBeOptimized = false;\n                        }\n                        (0, forEach_1.default)(optimizedCodes, function (code) {\n                            addToMapOfArrays(result, code, patternIdxToConfig[idx]);\n                        });\n                    }\n                }\n                else {\n                    if (options.ensureOptimizations) {\n                        (0, utils_1.PRINT_ERROR)(\"\".concat(reg_exp_1.failedOptimizationPrefixMsg) +\n                            \"\\tTokenType: <\".concat(currTokType.name, \"> is using a custom token pattern without providing <start_chars_hint> parameter.\\n\") +\n                            \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                            \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_OPTIMIZE\");\n                    }\n                    canBeOptimized = false;\n                }\n                return result;\n            }, []);\n        });\n    }\n    return {\n        emptyGroups: emptyGroups,\n        patternIdxToConfig: patternIdxToConfig,\n        charCodeToPatternIdxToConfig: charCodeToPatternIdxToConfig,\n        hasCustom: hasCustom,\n        canBeOptimized: canBeOptimized\n    };\n}\nexports.analyzeTokenTypes = analyzeTokenTypes;\nfunction validatePatterns(tokenTypes, validModesNames) {\n    var errors = [];\n    var missingResult = findMissingPatterns(tokenTypes);\n    errors = errors.concat(missingResult.errors);\n    var invalidResult = findInvalidPatterns(missingResult.valid);\n    var validTokenTypes = invalidResult.valid;\n    errors = errors.concat(invalidResult.errors);\n    errors = errors.concat(validateRegExpPattern(validTokenTypes));\n    errors = errors.concat(findInvalidGroupType(validTokenTypes));\n    errors = errors.concat(findModesThatDoNotExist(validTokenTypes, validModesNames));\n    errors = errors.concat(findUnreachablePatterns(validTokenTypes));\n    return errors;\n}\nexports.validatePatterns = validatePatterns;\nfunction validateRegExpPattern(tokenTypes) {\n    var errors = [];\n    var withRegExpPatterns = (0, filter_1.default)(tokenTypes, function (currTokType) {\n        return (0, isRegExp_1.default)(currTokType[PATTERN]);\n    });\n    errors = errors.concat(findEndOfInputAnchor(withRegExpPatterns));\n    errors = errors.concat(findStartOfInputAnchor(withRegExpPatterns));\n    errors = errors.concat(findUnsupportedFlags(withRegExpPatterns));\n    errors = errors.concat(findDuplicatePatterns(withRegExpPatterns));\n    errors = errors.concat(findEmptyMatchRegExps(withRegExpPatterns));\n    return errors;\n}\nfunction findMissingPatterns(tokenTypes) {\n    var tokenTypesWithMissingPattern = (0, filter_1.default)(tokenTypes, function (currType) {\n        return !(0, has_1.default)(currType, PATTERN);\n    });\n    var errors = (0, map_1.default)(tokenTypesWithMissingPattern, function (currType) {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- missing static 'PATTERN' property\",\n            type: lexer_public_1.LexerDefinitionErrorType.MISSING_PATTERN,\n            tokenTypes: [currType]\n        };\n    });\n    var valid = (0, difference_1.default)(tokenTypes, tokenTypesWithMissingPattern);\n    return { errors: errors, valid: valid };\n}\nexports.findMissingPatterns = findMissingPatterns;\nfunction findInvalidPatterns(tokenTypes) {\n    var tokenTypesWithInvalidPattern = (0, filter_1.default)(tokenTypes, function (currType) {\n        var pattern = currType[PATTERN];\n        return (!(0, isRegExp_1.default)(pattern) &&\n            !(0, isFunction_1.default)(pattern) &&\n            !(0, has_1.default)(pattern, \"exec\") &&\n            !(0, isString_1.default)(pattern));\n    });\n    var errors = (0, map_1.default)(tokenTypesWithInvalidPattern, function (currType) {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' can only be a RegExp, a\" +\n                \" Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\",\n            type: lexer_public_1.LexerDefinitionErrorType.INVALID_PATTERN,\n            tokenTypes: [currType]\n        };\n    });\n    var valid = (0, difference_1.default)(tokenTypes, tokenTypesWithInvalidPattern);\n    return { errors: errors, valid: valid };\n}\nexports.findInvalidPatterns = findInvalidPatterns;\nvar end_of_input = /[^\\\\][$]/;\nfunction findEndOfInputAnchor(tokenTypes) {\n    var EndAnchorFinder = /** @class */ (function (_super) {\n        __extends(EndAnchorFinder, _super);\n        function EndAnchorFinder() {\n            var _this = _super !== null && _super.apply(this, arguments) || this;\n            _this.found = false;\n            return _this;\n        }\n        EndAnchorFinder.prototype.visitEndAnchor = function (node) {\n            this.found = true;\n        };\n        return EndAnchorFinder;\n    }(regexp_to_ast_1.BaseRegExpVisitor));\n    var invalidRegex = (0, filter_1.default)(tokenTypes, function (currType) {\n        var pattern = currType.PATTERN;\n        try {\n            var regexpAst = (0, reg_exp_parser_1.getRegExpAst)(pattern);\n            var endAnchorVisitor = new EndAnchorFinder();\n            endAnchorVisitor.visit(regexpAst);\n            return endAnchorVisitor.found;\n        }\n        catch (e) {\n            // old behavior in case of runtime exceptions with regexp-to-ast.\n            /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n            return end_of_input.test(pattern.source);\n        }\n    });\n    var errors = (0, map_1.default)(invalidRegex, function (currType) {\n        return {\n            message: \"Unexpected RegExp Anchor Error:\\n\" +\n                \"\\tToken Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' cannot contain end of input anchor '$'\\n\" +\n                \"\\tSee chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n                \"\\tfor details.\",\n            type: lexer_public_1.LexerDefinitionErrorType.EOI_ANCHOR_FOUND,\n            tokenTypes: [currType]\n        };\n    });\n    return errors;\n}\nexports.findEndOfInputAnchor = findEndOfInputAnchor;\nfunction findEmptyMatchRegExps(tokenTypes) {\n    var matchesEmptyString = (0, filter_1.default)(tokenTypes, function (currType) {\n        var pattern = currType.PATTERN;\n        return pattern.test(\"\");\n    });\n    var errors = (0, map_1.default)(matchesEmptyString, function (currType) {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' must not match an empty string\",\n            type: lexer_public_1.LexerDefinitionErrorType.EMPTY_MATCH_PATTERN,\n            tokenTypes: [currType]\n        };\n    });\n    return errors;\n}\nexports.findEmptyMatchRegExps = findEmptyMatchRegExps;\nvar start_of_input = /[^\\\\[][\\^]|^\\^/;\nfunction findStartOfInputAnchor(tokenTypes) {\n    var StartAnchorFinder = /** @class */ (function (_super) {\n        __extends(StartAnchorFinder, _super);\n        function StartAnchorFinder() {\n            var _this = _super !== null && _super.apply(this, arguments) || this;\n            _this.found = false;\n            return _this;\n        }\n        StartAnchorFinder.prototype.visitStartAnchor = function (node) {\n            this.found = true;\n        };\n        return StartAnchorFinder;\n    }(regexp_to_ast_1.BaseRegExpVisitor));\n    var invalidRegex = (0, filter_1.default)(tokenTypes, function (currType) {\n        var pattern = currType.PATTERN;\n        try {\n            var regexpAst = (0, reg_exp_parser_1.getRegExpAst)(pattern);\n            var startAnchorVisitor = new StartAnchorFinder();\n            startAnchorVisitor.visit(regexpAst);\n            return startAnchorVisitor.found;\n        }\n        catch (e) {\n            // old behavior in case of runtime exceptions with regexp-to-ast.\n            /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n            return start_of_input.test(pattern.source);\n        }\n    });\n    var errors = (0, map_1.default)(invalidRegex, function (currType) {\n        return {\n            message: \"Unexpected RegExp Anchor Error:\\n\" +\n                \"\\tToken Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' cannot contain start of input anchor '^'\\n\" +\n                \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n                \"\\tfor details.\",\n            type: lexer_public_1.LexerDefinitionErrorType.SOI_ANCHOR_FOUND,\n            tokenTypes: [currType]\n        };\n    });\n    return errors;\n}\nexports.findStartOfInputAnchor = findStartOfInputAnchor;\nfunction findUnsupportedFlags(tokenTypes) {\n    var invalidFlags = (0, filter_1.default)(tokenTypes, function (currType) {\n        var pattern = currType[PATTERN];\n        return pattern instanceof RegExp && (pattern.multiline || pattern.global);\n    });\n    var errors = (0, map_1.default)(invalidFlags, function (currType) {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' may NOT contain global('g') or multiline('m')\",\n            type: lexer_public_1.LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,\n            tokenTypes: [currType]\n        };\n    });\n    return errors;\n}\nexports.findUnsupportedFlags = findUnsupportedFlags;\n// This can only test for identical duplicate RegExps, not semantically equivalent ones.\nfunction findDuplicatePatterns(tokenTypes) {\n    var found = [];\n    var identicalPatterns = (0, map_1.default)(tokenTypes, function (outerType) {\n        return (0, reduce_1.default)(tokenTypes, function (result, innerType) {\n            if (outerType.PATTERN.source === innerType.PATTERN.source &&\n                !(0, includes_1.default)(found, innerType) &&\n                innerType.PATTERN !== lexer_public_1.Lexer.NA) {\n                // this avoids duplicates in the result, each Token Type may only appear in one \"set\"\n                // in essence we are creating Equivalence classes on equality relation.\n                found.push(innerType);\n                result.push(innerType);\n                return result;\n            }\n            return result;\n        }, []);\n    });\n    identicalPatterns = (0, compact_1.default)(identicalPatterns);\n    var duplicatePatterns = (0, filter_1.default)(identicalPatterns, function (currIdenticalSet) {\n        return currIdenticalSet.length > 1;\n    });\n    var errors = (0, map_1.default)(duplicatePatterns, function (setOfIdentical) {\n        var tokenTypeNames = (0, map_1.default)(setOfIdentical, function (currType) {\n            return currType.name;\n        });\n        var dupPatternSrc = (0, first_1.default)(setOfIdentical).PATTERN;\n        return {\n            message: \"The same RegExp pattern ->\".concat(dupPatternSrc, \"<-\") +\n                \"has been used in all of the following Token Types: \".concat(tokenTypeNames.join(\", \"), \" <-\"),\n            type: lexer_public_1.LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,\n            tokenTypes: setOfIdentical\n        };\n    });\n    return errors;\n}\nexports.findDuplicatePatterns = findDuplicatePatterns;\nfunction findInvalidGroupType(tokenTypes) {\n    var invalidTypes = (0, filter_1.default)(tokenTypes, function (clazz) {\n        if (!(0, has_1.default)(clazz, \"GROUP\")) {\n            return false;\n        }\n        var group = clazz.GROUP;\n        return group !== lexer_public_1.Lexer.SKIPPED && group !== lexer_public_1.Lexer.NA && !(0, isString_1.default)(group);\n    });\n    var errors = (0, map_1.default)(invalidTypes, function (currType) {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\",\n            type: lexer_public_1.LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,\n            tokenTypes: [currType]\n        };\n    });\n    return errors;\n}\nexports.findInvalidGroupType = findInvalidGroupType;\nfunction findModesThatDoNotExist(tokenTypes, validModes) {\n    var invalidModes = (0, filter_1.default)(tokenTypes, function (clazz) {\n        return (clazz.PUSH_MODE !== undefined && !(0, includes_1.default)(validModes, clazz.PUSH_MODE));\n    });\n    var errors = (0, map_1.default)(invalidModes, function (tokType) {\n        var msg = \"Token Type: ->\".concat(tokType.name, \"<- static 'PUSH_MODE' value cannot refer to a Lexer Mode ->\").concat(tokType.PUSH_MODE, \"<-\") +\n            \"which does not exist\";\n        return {\n            message: msg,\n            type: lexer_public_1.LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,\n            tokenTypes: [tokType]\n        };\n    });\n    return errors;\n}\nexports.findModesThatDoNotExist = findModesThatDoNotExist;\nfunction findUnreachablePatterns(tokenTypes) {\n    var errors = [];\n    var canBeTested = (0, reduce_1.default)(tokenTypes, function (result, tokType, idx) {\n        var pattern = tokType.PATTERN;\n        if (pattern === lexer_public_1.Lexer.NA) {\n            return result;\n        }\n        // a more comprehensive validation for all forms of regExps would require\n        // deeper regExp analysis capabilities\n        if ((0, isString_1.default)(pattern)) {\n            result.push({ str: pattern, idx: idx, tokenType: tokType });\n        }\n        else if ((0, isRegExp_1.default)(pattern) && noMetaChar(pattern)) {\n            result.push({ str: pattern.source, idx: idx, tokenType: tokType });\n        }\n        return result;\n    }, []);\n    (0, forEach_1.default)(tokenTypes, function (tokType, testIdx) {\n        (0, forEach_1.default)(canBeTested, function (_a) {\n            var str = _a.str, idx = _a.idx, tokenType = _a.tokenType;\n            if (testIdx < idx && testTokenType(str, tokType.PATTERN)) {\n                var msg = \"Token: ->\".concat(tokenType.name, \"<- can never be matched.\\n\") +\n                    \"Because it appears AFTER the Token Type ->\".concat(tokType.name, \"<-\") +\n                    \"in the lexer's definition.\\n\" +\n                    \"See https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNREACHABLE\";\n                errors.push({\n                    message: msg,\n                    type: lexer_public_1.LexerDefinitionErrorType.UNREACHABLE_PATTERN,\n                    tokenTypes: [tokType, tokenType]\n                });\n            }\n        });\n    });\n    return errors;\n}\nexports.findUnreachablePatterns = findUnreachablePatterns;\nfunction testTokenType(str, pattern) {\n    /* istanbul ignore else */\n    if ((0, isRegExp_1.default)(pattern)) {\n        var regExpArray = pattern.exec(str);\n        return regExpArray !== null && regExpArray.index === 0;\n    }\n    else if ((0, isFunction_1.default)(pattern)) {\n        // maintain the API of custom patterns\n        return pattern(str, 0, [], {});\n    }\n    else if ((0, has_1.default)(pattern, \"exec\")) {\n        // maintain the API of custom patterns\n        return pattern.exec(str, 0, [], {});\n    }\n    else if (typeof pattern === \"string\") {\n        return pattern === str;\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nfunction noMetaChar(regExp) {\n    //https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp\n    var metaChars = [\n        \".\",\n        \"\\\\\",\n        \"[\",\n        \"]\",\n        \"|\",\n        \"^\",\n        \"$\",\n        \"(\",\n        \")\",\n        \"?\",\n        \"*\",\n        \"+\",\n        \"{\"\n    ];\n    return ((0, find_1.default)(metaChars, function (char) { return regExp.source.indexOf(char) !== -1; }) === undefined);\n}\nfunction addStartOfInput(pattern) {\n    var flags = pattern.ignoreCase ? \"i\" : \"\";\n    // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n    // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n    return new RegExp(\"^(?:\".concat(pattern.source, \")\"), flags);\n}\nexports.addStartOfInput = addStartOfInput;\nfunction addStickyFlag(pattern) {\n    var flags = pattern.ignoreCase ? \"iy\" : \"y\";\n    // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n    // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n    return new RegExp(\"\".concat(pattern.source), flags);\n}\nexports.addStickyFlag = addStickyFlag;\nfunction performRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n    var errors = [];\n    // some run time checks to help the end users.\n    if (!(0, has_1.default)(lexerDefinition, exports.DEFAULT_MODE)) {\n        errors.push({\n            message: \"A MultiMode Lexer cannot be initialized without a <\" +\n                exports.DEFAULT_MODE +\n                \"> property in its definition\\n\",\n            type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\n        });\n    }\n    if (!(0, has_1.default)(lexerDefinition, exports.MODES)) {\n        errors.push({\n            message: \"A MultiMode Lexer cannot be initialized without a <\" +\n                exports.MODES +\n                \"> property in its definition\\n\",\n            type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\n        });\n    }\n    if ((0, has_1.default)(lexerDefinition, exports.MODES) &&\n        (0, has_1.default)(lexerDefinition, exports.DEFAULT_MODE) &&\n        !(0, has_1.default)(lexerDefinition.modes, lexerDefinition.defaultMode)) {\n        errors.push({\n            message: \"A MultiMode Lexer cannot be initialized with a \".concat(exports.DEFAULT_MODE, \": <\").concat(lexerDefinition.defaultMode, \">\") +\n                \"which does not exist\\n\",\n            type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\n        });\n    }\n    if ((0, has_1.default)(lexerDefinition, exports.MODES)) {\n        (0, forEach_1.default)(lexerDefinition.modes, function (currModeValue, currModeName) {\n            (0, forEach_1.default)(currModeValue, function (currTokType, currIdx) {\n                if ((0, isUndefined_1.default)(currTokType)) {\n                    errors.push({\n                        message: \"A Lexer cannot be initialized using an undefined Token Type. Mode:\" +\n                            \"<\".concat(currModeName, \"> at index: <\").concat(currIdx, \">\\n\"),\n                        type: lexer_public_1.LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\n                    });\n                }\n                else if ((0, has_1.default)(currTokType, \"LONGER_ALT\")) {\n                    var longerAlt = (0, isArray_1.default)(currTokType.LONGER_ALT)\n                        ? currTokType.LONGER_ALT\n                        : [currTokType.LONGER_ALT];\n                    (0, forEach_1.default)(longerAlt, function (currLongerAlt) {\n                        if (!(0, isUndefined_1.default)(currLongerAlt) &&\n                            !(0, includes_1.default)(currModeValue, currLongerAlt)) {\n                            errors.push({\n                                message: \"A MultiMode Lexer cannot be initialized with a longer_alt <\".concat(currLongerAlt.name, \"> on token <\").concat(currTokType.name, \"> outside of mode <\").concat(currModeName, \">\\n\"),\n                                type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\n                            });\n                        }\n                    });\n                }\n            });\n        });\n    }\n    return errors;\n}\nexports.performRuntimeChecks = performRuntimeChecks;\nfunction performWarningRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n    var warnings = [];\n    var hasAnyLineBreak = false;\n    var allTokenTypes = (0, compact_1.default)((0, flatten_1.default)((0, values_1.default)(lexerDefinition.modes)));\n    var concreteTokenTypes = (0, reject_1.default)(allTokenTypes, function (currType) { return currType[PATTERN] === lexer_public_1.Lexer.NA; });\n    var terminatorCharCodes = getCharCodes(lineTerminatorCharacters);\n    if (trackLines) {\n        (0, forEach_1.default)(concreteTokenTypes, function (tokType) {\n            var currIssue = checkLineBreaksIssues(tokType, terminatorCharCodes);\n            if (currIssue !== false) {\n                var message = buildLineBreakIssueMessage(tokType, currIssue);\n                var warningDescriptor = {\n                    message: message,\n                    type: currIssue.issue,\n                    tokenType: tokType\n                };\n                warnings.push(warningDescriptor);\n            }\n            else {\n                // we don't want to attempt to scan if the user explicitly specified the line_breaks option.\n                if ((0, has_1.default)(tokType, \"LINE_BREAKS\")) {\n                    if (tokType.LINE_BREAKS === true) {\n                        hasAnyLineBreak = true;\n                    }\n                }\n                else {\n                    if ((0, reg_exp_1.canMatchCharCode)(terminatorCharCodes, tokType.PATTERN)) {\n                        hasAnyLineBreak = true;\n                    }\n                }\n            }\n        });\n    }\n    if (trackLines && !hasAnyLineBreak) {\n        warnings.push({\n            message: \"Warning: No LINE_BREAKS Found.\\n\" +\n                \"\\tThis Lexer has been defined to track line and column information,\\n\" +\n                \"\\tBut none of the Token Types can be identified as matching a line terminator.\\n\" +\n                \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#LINE_BREAKS \\n\" +\n                \"\\tfor details.\",\n            type: lexer_public_1.LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS\n        });\n    }\n    return warnings;\n}\nexports.performWarningRuntimeChecks = performWarningRuntimeChecks;\nfunction cloneEmptyGroups(emptyGroups) {\n    var clonedResult = {};\n    var groupKeys = (0, keys_1.default)(emptyGroups);\n    (0, forEach_1.default)(groupKeys, function (currKey) {\n        var currGroupValue = emptyGroups[currKey];\n        /* istanbul ignore else */\n        if ((0, isArray_1.default)(currGroupValue)) {\n            clonedResult[currKey] = [];\n        }\n        else {\n            throw Error(\"non exhaustive match\");\n        }\n    });\n    return clonedResult;\n}\nexports.cloneEmptyGroups = cloneEmptyGroups;\n// TODO: refactor to avoid duplication\nfunction isCustomPattern(tokenType) {\n    var pattern = tokenType.PATTERN;\n    /* istanbul ignore else */\n    if ((0, isRegExp_1.default)(pattern)) {\n        return false;\n    }\n    else if ((0, isFunction_1.default)(pattern)) {\n        // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n        return true;\n    }\n    else if ((0, has_1.default)(pattern, \"exec\")) {\n        // ICustomPattern\n        return true;\n    }\n    else if ((0, isString_1.default)(pattern)) {\n        return false;\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nexports.isCustomPattern = isCustomPattern;\nfunction isShortPattern(pattern) {\n    if ((0, isString_1.default)(pattern) && pattern.length === 1) {\n        return pattern.charCodeAt(0);\n    }\n    else {\n        return false;\n    }\n}\nexports.isShortPattern = isShortPattern;\n/**\n * Faster than using a RegExp for default newline detection during lexing.\n */\nexports.LineTerminatorOptimizedTester = {\n    // implements /\\n|\\r\\n?/g.test\n    test: function (text) {\n        var len = text.length;\n        for (var i = this.lastIndex; i < len; i++) {\n            var c = text.charCodeAt(i);\n            if (c === 10) {\n                this.lastIndex = i + 1;\n                return true;\n            }\n            else if (c === 13) {\n                if (text.charCodeAt(i + 1) === 10) {\n                    this.lastIndex = i + 2;\n                }\n                else {\n                    this.lastIndex = i + 1;\n                }\n                return true;\n            }\n        }\n        return false;\n    },\n    lastIndex: 0\n};\nfunction checkLineBreaksIssues(tokType, lineTerminatorCharCodes) {\n    if ((0, has_1.default)(tokType, \"LINE_BREAKS\")) {\n        // if the user explicitly declared the line_breaks option we will respect their choice\n        // and assume it is correct.\n        return false;\n    }\n    else {\n        /* istanbul ignore else */\n        if ((0, isRegExp_1.default)(tokType.PATTERN)) {\n            try {\n                // TODO: why is the casting suddenly needed?\n                (0, reg_exp_1.canMatchCharCode)(lineTerminatorCharCodes, tokType.PATTERN);\n            }\n            catch (e) {\n                /* istanbul ignore next - to test this we would have to mock <canMatchCharCode> to throw an error */\n                return {\n                    issue: lexer_public_1.LexerDefinitionErrorType.IDENTIFY_TERMINATOR,\n                    errMsg: e.message\n                };\n            }\n            return false;\n        }\n        else if ((0, isString_1.default)(tokType.PATTERN)) {\n            // string literal patterns can always be analyzed to detect line terminator usage\n            return false;\n        }\n        else if (isCustomPattern(tokType)) {\n            // custom token types\n            return { issue: lexer_public_1.LexerDefinitionErrorType.CUSTOM_LINE_BREAK };\n        }\n        else {\n            throw Error(\"non exhaustive match\");\n        }\n    }\n}\nfunction buildLineBreakIssueMessage(tokType, details) {\n    /* istanbul ignore else */\n    if (details.issue === lexer_public_1.LexerDefinitionErrorType.IDENTIFY_TERMINATOR) {\n        return (\"Warning: unable to identify line terminator usage in pattern.\\n\" +\n            \"\\tThe problem is in the <\".concat(tokType.name, \"> Token Type\\n\") +\n            \"\\t Root cause: \".concat(details.errMsg, \".\\n\") +\n            \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#IDENTIFY_TERMINATOR\");\n    }\n    else if (details.issue === lexer_public_1.LexerDefinitionErrorType.CUSTOM_LINE_BREAK) {\n        return (\"Warning: A Custom Token Pattern should specify the <line_breaks> option.\\n\" +\n            \"\\tThe problem is in the <\".concat(tokType.name, \"> Token Type\\n\") +\n            \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_LINE_BREAK\");\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nexports.buildLineBreakIssueMessage = buildLineBreakIssueMessage;\nfunction getCharCodes(charsOrCodes) {\n    var charCodes = (0, map_1.default)(charsOrCodes, function (numOrString) {\n        if ((0, isString_1.default)(numOrString)) {\n            return numOrString.charCodeAt(0);\n        }\n        else {\n            return numOrString;\n        }\n    });\n    return charCodes;\n}\nfunction addToMapOfArrays(map, key, value) {\n    if (map[key] === undefined) {\n        map[key] = [value];\n    }\n    else {\n        map[key].push(value);\n    }\n}\nexports.minOptimizationVal = 256;\n/**\n * We are mapping charCode above ASCI (256) into buckets each in the size of 256.\n * This is because ASCI are the most common start chars so each one of those will get its own\n * possible token configs vector.\n *\n * Tokens starting with charCodes \"above\" ASCI are uncommon, so we can \"afford\"\n * to place these into buckets of possible token configs, What we gain from\n * this is avoiding the case of creating an optimization 'charCodeToPatternIdxToConfig'\n * which would contain 10,000+ arrays of small size (e.g unicode Identifiers scenario).\n * Our 'charCodeToPatternIdxToConfig' max size will now be:\n * 256 + (2^16 / 2^8) - 1 === 511\n *\n * note the hack for fast division integer part extraction\n * See: https://stackoverflow.com/a/4228528\n */\nvar charCodeToOptimizedIdxMap = [];\nfunction charCodeToOptimizedIndex(charCode) {\n    return charCode < exports.minOptimizationVal\n        ? charCode\n        : charCodeToOptimizedIdxMap[charCode];\n}\nexports.charCodeToOptimizedIndex = charCodeToOptimizedIndex;\n/**\n * This is a compromise between cold start / hot running performance\n * Creating this array takes ~3ms on a modern machine,\n * But if we perform the computation at runtime as needed the CSS Lexer benchmark\n * performance degrades by ~10%\n *\n * TODO: Perhaps it should be lazy initialized only if a charCode > 255 is used.\n */\nfunction initCharCodeToOptimizedIndexMap() {\n    if ((0, isEmpty_1.default)(charCodeToOptimizedIdxMap)) {\n        charCodeToOptimizedIdxMap = new Array(65536);\n        for (var i = 0; i < 65536; i++) {\n            charCodeToOptimizedIdxMap[i] = i > 255 ? 255 + ~~(i / 255) : i;\n        }\n    }\n}\n//# sourceMappingURL=lexer.js.map"]},"metadata":{},"sourceType":"script"}